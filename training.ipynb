{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9219211,"sourceType":"datasetVersion","datasetId":5448479}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-25T14:12:57.256347Z","iopub.execute_input":"2024-08-25T14:12:57.257206Z","iopub.status.idle":"2024-08-25T14:12:57.263255Z","shell.execute_reply.started":"2024-08-25T14:12:57.257171Z","shell.execute_reply":"2024-08-25T14:12:57.262417Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install apex","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:12:57.276258Z","iopub.execute_input":"2024-08-25T14:12:57.276727Z","iopub.status.idle":"2024-08-25T14:13:42.329897Z","shell.execute_reply.started":"2024-08-25T14:12:57.276694Z","shell.execute_reply":"2024-08-25T14:13:42.328891Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting apex\n  Downloading apex-0.9.10dev.tar.gz (36 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting cryptacular (from apex)\n  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting zope.sqlalchemy (from apex)\n  Downloading zope.sqlalchemy-3.1-py3-none-any.whl.metadata (18 kB)\nCollecting velruse>=1.0.3 (from apex)\n  Downloading velruse-1.1.1.tar.gz (709 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyramid>1.1.2 (from apex)\n  Downloading pyramid-2.0.2-py3-none-any.whl.metadata (20 kB)\nCollecting pyramid_mailer (from apex)\n  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from apex) (2.32.3)\nCollecting wtforms (from apex)\n  Downloading wtforms-3.1.2-py3-none-any.whl.metadata (5.3 kB)\nCollecting wtforms-recaptcha (from apex)\n  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl.metadata (3.1 kB)\nCollecting hupper>=1.5 (from pyramid>1.1.2->apex)\n  Downloading hupper-1.12.1-py3-none-any.whl.metadata (3.7 kB)\nCollecting plaster (from pyramid>1.1.2->apex)\n  Downloading plaster-1.1.2-py2.py3-none-any.whl.metadata (6.4 kB)\nCollecting plaster-pastedeploy (from pyramid>1.1.2->apex)\n  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl.metadata (8.1 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from pyramid>1.1.2->apex) (69.0.3)\nCollecting translationstring>=0.4 (from pyramid>1.1.2->apex)\n  Downloading translationstring-1.4-py2.py3-none-any.whl.metadata (4.1 kB)\nCollecting venusian>=1.0 (from pyramid>1.1.2->apex)\n  Downloading venusian-3.1.0-py3-none-any.whl.metadata (10 kB)\nCollecting webob>=1.8.3 (from pyramid>1.1.2->apex)\n  Downloading WebOb-1.8.8-py2.py3-none-any.whl.metadata (11 kB)\nCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex)\n  Downloading zope.deprecation-5.0-py3-none-any.whl.metadata (5.1 kB)\nCollecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex)\n  Downloading zope.interface-7.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from velruse>=1.0.3->apex) (1.3.1)\nCollecting anykeystore (from velruse>=1.0.3->apex)\n  Downloading anykeystore-0.2.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting python3-openid (from velruse>=1.0.3->apex)\n  Downloading python3_openid-3.2.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting pbkdf2 (from cryptacular->apex)\n  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting repoze.sendmail>=4.1 (from pyramid_mailer->apex)\n  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl.metadata (8.3 kB)\nCollecting transaction (from pyramid_mailer->apex)\n  Downloading transaction-4.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->apex) (2024.7.4)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from wtforms->apex) (2.1.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (21.3)\nRequirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from zope.sqlalchemy->apex) (2.0.25)\nRequirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (4.9.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->zope.sqlalchemy->apex) (3.1.1)\nCollecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex)\n  Downloading PasteDeploy-3.1.0-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from python3-openid->velruse>=1.0.3->apex) (0.7.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.2.2)\nDownloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\nDownloading wtforms-3.1.2-py3-none-any.whl (145 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\nDownloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\nDownloading hupper-1.12.1-py3-none-any.whl (22 kB)\nDownloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transaction-4.0-py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\nDownloading venusian-3.1.0-py3-none-any.whl (13 kB)\nDownloading WebOb-1.8.8-py2.py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\nDownloading zope.interface-7.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\nDownloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\nDownloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\nBuilding wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n  Building wheel for apex (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46442 sha256=4c06596da502141a9dce52d9abff8098d44f6b300a5aa9b01d4eaa902705af60\n  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n  Building wheel for velruse (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50909 sha256=3e98c8083272ad7e6e7dfb7a23c5fe06f9e248582019e1ddbcc8be9395239dbb\n  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=28236 sha256=3bfb24ae6e537d0ea015559750156cefbae61ea902c0d9a10ad781ff7a8a8cdf\n  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n  Building wheel for anykeystore (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=dd4e447f6cf1c9c8752af2cde36f6722b1d0ba7f2cbd1776af79752c1dc72d7e\n  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n  Building wheel for pbkdf2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5082 sha256=03d28729de95264e99fe644036071162085f48b80e171e713397d7d321e81516\n  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\nSuccessfully built apex velruse cryptacular anykeystore pbkdf2\nInstalling collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, python3-openid, plaster, PasteDeploy, hupper, cryptacular, wtforms-recaptcha, transaction, plaster-pastedeploy, zope.sqlalchemy, repoze.sendmail, pyramid, velruse, pyramid_mailer, apex\nSuccessfully installed PasteDeploy-3.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 hupper-1.12.1 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 transaction-4.0 translationstring-1.4 velruse-1.1.1 venusian-3.1.0 webob-1.8.8 wtforms-3.1.2 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-7.0.1 zope.sqlalchemy-3.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nimport time\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport albumentations\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport cv2\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.image as mpimg\n\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport random\n# import apex\n# from apex import amp","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:42.332206Z","iopub.execute_input":"2024-08-25T14:13:42.332964Z","iopub.status.idle":"2024-08-25T14:13:50.968927Z","shell.execute_reply.started":"2024-08-25T14:13:42.332925Z","shell.execute_reply":"2024-08-25T14:13:50.968146Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traindf= pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:50.970187Z","iopub.execute_input":"2024-08-25T14:13:50.970896Z","iopub.status.idle":"2024-08-25T14:13:50.975301Z","shell.execute_reply.started":"2024-08-25T14:13:50.970862Z","shell.execute_reply":"2024-08-25T14:13:50.974330Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# traindf['iddx_full']","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:50.977376Z","iopub.execute_input":"2024-08-25T14:13:50.977731Z","iopub.status.idle":"2024-08-25T14:13:50.987256Z","shell.execute_reply.started":"2024-08-25T14:13:50.977707Z","shell.execute_reply":"2024-08-25T14:13:50.986425Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Will use idx full as target column","metadata":{}},{"cell_type":"markdown","source":"## Find category relation between target and idX_full","metadata":{}},{"cell_type":"code","source":"# # Group by 'target' and get unique values in 'iddx_full'\n# unique_values = traindf.groupby('target')['iddx_full'].unique()\n\n# # Convert the result to a dictionary for better readability\n# unique_values_dict = unique_values.to_dict()\n\n# print(\"Unique values of 'iddx_full' for each category in 'target':\")\n# print(unique_values_dict[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:50.988373Z","iopub.execute_input":"2024-08-25T14:13:50.988699Z","iopub.status.idle":"2024-08-25T14:13:50.998315Z","shell.execute_reply.started":"2024-08-25T14:13:50.988667Z","shell.execute_reply":"2024-08-25T14:13:50.997531Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# print(unique_values_dict[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:50.999275Z","iopub.execute_input":"2024-08-25T14:13:50.999542Z","iopub.status.idle":"2024-08-25T14:13:51.008356Z","shell.execute_reply.started":"2024-08-25T14:13:50.999512Z","shell.execute_reply":"2024-08-25T14:13:51.007499Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Remove Not required columns","metadata":{}},{"cell_type":"code","source":"test_na_columns = [\n    \"lesion_id\",\n    \"iddx_1\",\n    \"iddx_2\",\n    \"iddx_3\",\n    \"iddx_4\",\n    \"iddx_5\",\n    \"mel_mitotic_index\",\n    \"mel_thick_mm\",\n    \"tbp_lv_dnn_lesion_confidence\",\n    \"copyright_license\",\n    \"attribution\",\n    \"patient_id\",\n    \"image_type\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.009362Z","iopub.execute_input":"2024-08-25T14:13:51.009619Z","iopub.status.idle":"2024-08-25T14:13:51.018805Z","shell.execute_reply.started":"2024-08-25T14:13:51.009597Z","shell.execute_reply":"2024-08-25T14:13:51.018006Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# tdf  = traindf.drop(columns = test_na_columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.019793Z","iopub.execute_input":"2024-08-25T14:13:51.020095Z","iopub.status.idle":"2024-08-25T14:13:51.029203Z","shell.execute_reply.started":"2024-08-25T14:13:51.020073Z","shell.execute_reply":"2024-08-25T14:13:51.028454Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# tdf.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.030278Z","iopub.execute_input":"2024-08-25T14:13:51.030542Z","iopub.status.idle":"2024-08-25T14:13:51.043250Z","shell.execute_reply.started":"2024-08-25T14:13:51.030519Z","shell.execute_reply":"2024-08-25T14:13:51.042018Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Look for column with missing values","metadata":{}},{"cell_type":"code","source":"# cols_with_nulls = traindf.columns[traindf.isnull().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.046920Z","iopub.execute_input":"2024-08-25T14:13:51.047250Z","iopub.status.idle":"2024-08-25T14:13:51.052710Z","shell.execute_reply.started":"2024-08-25T14:13:51.047227Z","shell.execute_reply":"2024-08-25T14:13:51.052026Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# traindf['sex'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.053752Z","iopub.execute_input":"2024-08-25T14:13:51.054074Z","iopub.status.idle":"2024-08-25T14:13:51.062432Z","shell.execute_reply.started":"2024-08-25T14:13:51.054051Z","shell.execute_reply":"2024-08-25T14:13:51.061561Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numeric column with null values remove ","metadata":{}},{"cell_type":"code","source":"# tdf['tbp_lv_location_simple'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.063504Z","iopub.execute_input":"2024-08-25T14:13:51.063766Z","iopub.status.idle":"2024-08-25T14:13:51.071777Z","shell.execute_reply.started":"2024-08-25T14:13:51.063744Z","shell.execute_reply":"2024-08-25T14:13:51.071007Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# tdf['anatom_site_general'].mode()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.072855Z","iopub.execute_input":"2024-08-25T14:13:51.073263Z","iopub.status.idle":"2024-08-25T14:13:51.080611Z","shell.execute_reply.started":"2024-08-25T14:13:51.073193Z","shell.execute_reply":"2024-08-25T14:13:51.079832Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# tdf['age_approx'].median()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.082040Z","iopub.execute_input":"2024-08-25T14:13:51.082320Z","iopub.status.idle":"2024-08-25T14:13:51.090266Z","shell.execute_reply.started":"2024-08-25T14:13:51.082298Z","shell.execute_reply":"2024-08-25T14:13:51.089506Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#  tdf['age_approx'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.091284Z","iopub.execute_input":"2024-08-25T14:13:51.091533Z","iopub.status.idle":"2024-08-25T14:13:51.099958Z","shell.execute_reply.started":"2024-08-25T14:13:51.091511Z","shell.execute_reply":"2024-08-25T14:13:51.098997Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#  tdf['anatom_site_general'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.101075Z","iopub.execute_input":"2024-08-25T14:13:51.101414Z","iopub.status.idle":"2024-08-25T14:13:51.109885Z","shell.execute_reply.started":"2024-08-25T14:13:51.101381Z","shell.execute_reply":"2024-08-25T14:13:51.109153Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#  tdf['sex'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.111036Z","iopub.execute_input":"2024-08-25T14:13:51.111297Z","iopub.status.idle":"2024-08-25T14:13:51.120037Z","shell.execute_reply.started":"2024-08-25T14:13:51.111275Z","shell.execute_reply":"2024-08-25T14:13:51.119355Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Read training Data","metadata":{}},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'iddx_full'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple']\nfeature_cols = num_cols + new_num_cols + cat_cols ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.121545Z","iopub.execute_input":"2024-08-25T14:13:51.121778Z","iopub.status.idle":"2024-08-25T14:13:51.136987Z","shell.execute_reply.started":"2024-08-25T14:13:51.121757Z","shell.execute_reply":"2024-08-25T14:13:51.136183Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"len(new_num_cols)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.138115Z","iopub.execute_input":"2024-08-25T14:13:51.138381Z","iopub.status.idle":"2024-08-25T14:13:51.153058Z","shell.execute_reply.started":"2024-08-25T14:13:51.138359Z","shell.execute_reply":"2024-08-25T14:13:51.152242Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"42"},"metadata":{}}]},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.DataFrame(path)\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .to_pandas()\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.154503Z","iopub.execute_input":"2024-08-25T14:13:51.154833Z","iopub.status.idle":"2024-08-25T14:13:51.179389Z","shell.execute_reply.started":"2024-08-25T14:13:51.154803Z","shell.execute_reply":"2024-08-25T14:13:51.178464Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train,is_test = False):\n\n    global cat_cols\n\n    df_train.drop(columns = test_na_columns,inplace=True)\n\n    # Select numerical columns\n    numerical_cols = df_train.select_dtypes(include=['number']).columns.tolist()\n    \n    # Initialize the scaler\n    scaler = StandardScaler()\n    numerical_cols.remove('target')\n    # Fit the scaler on the numerical data and transform\n    df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n\n    # Save the scaler object\n    with open('scaler.pkl', 'wb') as file:\n        pickle.dump(scaler, file)\n\n    encoder = OneHotEncoder(sparse_output=False)\n    encoder.fit(df_train[cat_cols])\n\n    MAX_CAT_VAR_NAME_SIZE = 30\n    new_cat_cols = [x.replace(\" \", \"_\")[:MAX_CAT_VAR_NAME_SIZE] for x in encoder.get_feature_names_out()]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n        \n#     for col in cat_cols:\n#         feature_cols.remove(col)\n\n    df_train.drop(columns = cat_cols,inplace=True)\n\n    #feature_cols.extend(new_cat_cols)\n    #cat_cols = new_cat_cols\n\n    if is_test == False:\n        enc = OrdinalEncoder()\n        enc.fit(df_train[[target_col]])\n        df_train[target_col] = enc.transform(df_train[[target_col]])\n        with open('ordinalEndoder.pkl', 'wb') as file:\n            pickle.dump(enc, file)\n\n    return df_train","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.180319Z","iopub.execute_input":"2024-08-25T14:13:51.180572Z","iopub.status.idle":"2024-08-25T14:13:51.194365Z","shell.execute_reply.started":"2024-08-25T14:13:51.180550Z","shell.execute_reply":"2024-08-25T14:13:51.193514Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df(data_dir,use_meta):\n    df = pd.read_csv(data_dir)\n\n    mode_values = df.select_dtypes(include=['object']).mode().iloc[0]\n    df.fillna(mode_values, inplace=True)\n\n    median_values = df.select_dtypes(include=['number']).median()\n\n    # Fill null values with the median values\n    df.fillna(median_values, inplace=True)\n    \n    df = read_data(df)\n    df = preprocess(df)\n    \n    if use_meta:\n        dataset_features = df.columns.to_list()\n        meta_features = list(set(dataset_features)-set(['target','isic_id','iddx_full']))\n        n_meta_features = len(meta_features)\n    else:\n        meta_features = None\n        n_meta_features = 0\n        \n    mel_idx = 1\n    return df, meta_features, n_meta_features, mel_idx","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.195374Z","iopub.execute_input":"2024-08-25T14:13:51.195692Z","iopub.status.idle":"2024-08-25T14:13:51.207326Z","shell.execute_reply.started":"2024-08-25T14:13:51.195661Z","shell.execute_reply":"2024-08-25T14:13:51.206508Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(train_path)\n\n# mode_values = df_train.select_dtypes(include=['object']).mode().iloc[0]\n# df_train.fillna(mode_values, inplace=True)\n\n# median_values = df_train.select_dtypes(include=['number']).median()\n\n# # Fill null values with the median values\n# df_train.fillna(median_values, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.208360Z","iopub.execute_input":"2024-08-25T14:13:51.208914Z","iopub.status.idle":"2024-08-25T14:13:51.220218Z","shell.execute_reply.started":"2024-08-25T14:13:51.208884Z","shell.execute_reply":"2024-08-25T14:13:51.219491Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# df_train = read_data(df_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.221181Z","iopub.execute_input":"2024-08-25T14:13:51.221439Z","iopub.status.idle":"2024-08-25T14:13:51.229554Z","shell.execute_reply.started":"2024-08-25T14:13:51.221417Z","shell.execute_reply":"2024-08-25T14:13:51.228759Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# df_train = preprocess(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.230515Z","iopub.execute_input":"2024-08-25T14:13:51.230769Z","iopub.status.idle":"2024-08-25T14:13:51.240464Z","shell.execute_reply.started":"2024-08-25T14:13:51.230748Z","shell.execute_reply":"2024-08-25T14:13:51.239746Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.241442Z","iopub.execute_input":"2024-08-25T14:13:51.241708Z","iopub.status.idle":"2024-08-25T14:13:51.250685Z","shell.execute_reply.started":"2024-08-25T14:13:51.241686Z","shell.execute_reply":"2024-08-25T14:13:51.249775Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# df_train.columns[df_train.isnull().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.251765Z","iopub.execute_input":"2024-08-25T14:13:51.252062Z","iopub.status.idle":"2024-08-25T14:13:51.260256Z","shell.execute_reply.started":"2024-08-25T14:13:51.252040Z","shell.execute_reply":"2024-08-25T14:13:51.259382Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# print(df_train.columns.to_list())","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.268401Z","iopub.execute_input":"2024-08-25T14:13:51.268737Z","iopub.status.idle":"2024-08-25T14:13:51.272346Z","shell.execute_reply.started":"2024-08-25T14:13:51.268714Z","shell.execute_reply":"2024-08-25T14:13:51.271454Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_rows', 60)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.273416Z","iopub.execute_input":"2024-08-25T14:13:51.273736Z","iopub.status.idle":"2024-08-25T14:13:51.281471Z","shell.execute_reply.started":"2024-08-25T14:13:51.273707Z","shell.execute_reply":"2024-08-25T14:13:51.280590Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# print(len(df_train.columns.to_list()))","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.282538Z","iopub.execute_input":"2024-08-25T14:13:51.282794Z","iopub.status.idle":"2024-08-25T14:13:51.291223Z","shell.execute_reply.started":"2024-08-25T14:13:51.282769Z","shell.execute_reply":"2024-08-25T14:13:51.290328Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# df_train['index_age_size_symmetry'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.292263Z","iopub.execute_input":"2024-08-25T14:13:51.292595Z","iopub.status.idle":"2024-08-25T14:13:51.300426Z","shell.execute_reply.started":"2024-08-25T14:13:51.292563Z","shell.execute_reply":"2024-08-25T14:13:51.299619Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# df_train.iloc[10070].iddx_full","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.301466Z","iopub.execute_input":"2024-08-25T14:13:51.302393Z","iopub.status.idle":"2024-08-25T14:13:51.309395Z","shell.execute_reply.started":"2024-08-25T14:13:51.302367Z","shell.execute_reply":"2024-08-25T14:13:51.308471Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# df_train.to_csv('/kaggle/working/preprocessDataset.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.310583Z","iopub.execute_input":"2024-08-25T14:13:51.311118Z","iopub.status.idle":"2024-08-25T14:13:51.318524Z","shell.execute_reply.started":"2024-08-25T14:13:51.311093Z","shell.execute_reply":"2024-08-25T14:13:51.317807Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.319487Z","iopub.execute_input":"2024-08-25T14:13:51.319799Z","iopub.status.idle":"2024-08-25T14:13:51.328601Z","shell.execute_reply.started":"2024-08-25T14:13:51.319769Z","shell.execute_reply":"2024-08-25T14:13:51.327726Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Removing the Psychic from dataset","metadata":{}},{"cell_type":"code","source":"# pdf = pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.330483Z","iopub.execute_input":"2024-08-25T14:13:51.330794Z","iopub.status.idle":"2024-08-25T14:13:51.338773Z","shell.execute_reply.started":"2024-08-25T14:13:51.330770Z","shell.execute_reply":"2024-08-25T14:13:51.338018Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# df_selfclean = pd.read_csv('/kaggle/input/isic-2024-challenge-selfclean-scores/ISIC_2024_Challenge_SelfClean_Scores.csv')\n# df_selfclean.drop(columns=['irrelevant_ranking', 'label_error_ranking'], inplace=True)\n# df_selfclean.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.339816Z","iopub.execute_input":"2024-08-25T14:13:51.340096Z","iopub.status.idle":"2024-08-25T14:13:51.348615Z","shell.execute_reply.started":"2024-08-25T14:13:51.340072Z","shell.execute_reply":"2024-08-25T14:13:51.347769Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# pdf = pdf.merge(df_selfclean, on=[\"isic_id\", \"patient_id\"])\n# pdf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.349551Z","iopub.execute_input":"2024-08-25T14:13:51.351118Z","iopub.status.idle":"2024-08-25T14:13:51.357688Z","shell.execute_reply.started":"2024-08-25T14:13:51.351094Z","shell.execute_reply":"2024-08-25T14:13:51.356776Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# pdf[\"label_error_score\"].hist(bins=\"sqrt\")\n# plt.yscale(\"log\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.358792Z","iopub.execute_input":"2024-08-25T14:13:51.359216Z","iopub.status.idle":"2024-08-25T14:13:51.366749Z","shell.execute_reply.started":"2024-08-25T14:13:51.359177Z","shell.execute_reply":"2024-08-25T14:13:51.365909Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"# Remove Hair","metadata":{}},{"cell_type":"code","source":"#path_list = [f\"/kaggle/input/isic-2024-challenge/train-image/image/{id}.jpg\" for id in df_train.isic_id]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.367650Z","iopub.execute_input":"2024-08-25T14:13:51.369204Z","iopub.status.idle":"2024-08-25T14:13:51.376470Z","shell.execute_reply.started":"2024-08-25T14:13:51.369180Z","shell.execute_reply":"2024-08-25T14:13:51.375559Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"\n\n#image_hair = np.array(path_list)[[1202, 216, 8854, 1174, 131, 174]]\n\ndef hair_remove(image):\n    # convert image to grayScale\n    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n    # kernel for morphologyEx\n    kernel = cv2.getStructuringElement(1,(17,17))\n\n    # apply MORPH_BLACKHAT to grayScale image\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n    # apply thresholding to blackhat\n    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n\n    # inpaint with original image and threshold image\n    final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n\n    return final_image\n\n# Show the Augmented Images\n# plt.figure(figsize=(16,3))\n# plt.suptitle(\"Original Hairy Images\", fontsize = 16)\n    \n# for k, path in enumerate(image_hair[:5]):\n#     image = mpimg.imread(path)\n#     image = cv2.resize(image,(300, 300))\n        \n#     plt.subplot(1, 6, k+1)\n#     plt.imshow(image)\n#     plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.377482Z","iopub.execute_input":"2024-08-25T14:13:51.377732Z","iopub.status.idle":"2024-08-25T14:13:51.390711Z","shell.execute_reply.started":"2024-08-25T14:13:51.377711Z","shell.execute_reply":"2024-08-25T14:13:51.389889Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# # Show the sample\n# plt.figure(figsize=(16,3))\n# plt.suptitle(\"Non Hairy Images\", fontsize = 16)\n    \n# for k, path in enumerate(image_hair):\n#     image = mpimg.imread(path)\n#     image = cv2.resize(image,(300, 300))\n#     image = hair_remove(image)\n        \n#     plt.subplot(1, 6, k+1)\n#     plt.imshow(image)\n#     plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.391850Z","iopub.execute_input":"2024-08-25T14:13:51.392243Z","iopub.status.idle":"2024-08-25T14:13:51.400272Z","shell.execute_reply.started":"2024-08-25T14:13:51.392183Z","shell.execute_reply":"2024-08-25T14:13:51.399571Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"# prepare dataset for iamges","metadata":{}},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, csv, mode, meta_features, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.mode = mode\n        self.use_meta = meta_features is not None\n        self.meta_features = meta_features\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n\n        row = self.csv.iloc[index]\n        #print(row)\n        train_image_base_path  = f'/kaggle/input/isic-2024-challenge/train-image/image/{row.isic_id}.jpg'\n        #print(\"filePath:\"+train_image_base_path)\n        image = cv2.imread(train_image_base_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        #image = hair_remove(image)\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n        #print(self.csv.iloc[index][self.meta_features])\n        if self.use_meta:\n            data = (torch.tensor(image).float(), torch.tensor(self.csv.iloc[index][self.meta_features]).float())\n        else:\n            data = torch.tensor(image).float()\n\n        if self.mode == 'test':\n            return data\n        else:\n            return data, torch.tensor(self.csv.iloc[index].target).long()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.401392Z","iopub.execute_input":"2024-08-25T14:13:51.401663Z","iopub.status.idle":"2024-08-25T14:13:51.412505Z","shell.execute_reply.started":"2024-08-25T14:13:51.401642Z","shell.execute_reply":"2024-08-25T14:13:51.411692Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"def get_transforms(image_size):\n\n    transforms_train = albumentations.Compose([\n        albumentations.Transpose(p=0.5),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,p=0.75),\n        albumentations.OneOf([\n            albumentations.MotionBlur(blur_limit=5),\n            albumentations.MedianBlur(blur_limit=5),\n            albumentations.GaussianBlur(blur_limit=5),\n            albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n        ], p=0.7),\n\n        albumentations.OneOf([\n            albumentations.OpticalDistortion(distort_limit=1.0),\n            albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n            albumentations.ElasticTransform(alpha=3),\n        ], p=0.7),\n\n        albumentations.CLAHE(clip_limit=4.0, p=0.7),\n        #albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n        albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n        albumentations.Resize(image_size, image_size),\n        albumentations.CoarseDropout(max_holes= 3,max_height = int(image_size * 0.20),min_holes = 1,max_width =int(image_size * 0.20),p=0.7 ),\n        albumentations.Normalize()\n    ])\n\n    transforms_val = albumentations.Compose([\n        albumentations.Resize(image_size, image_size),\n        albumentations.Normalize()\n    ])\n\n    return transforms_train, transforms_val","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.413501Z","iopub.execute_input":"2024-08-25T14:13:51.413793Z","iopub.status.idle":"2024-08-25T14:13:51.427072Z","shell.execute_reply.started":"2024-08-25T14:13:51.413770Z","shell.execute_reply":"2024-08-25T14:13:51.426239Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"# Split and Prepare Dataset","metadata":{}},{"cell_type":"code","source":"# albumentations.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.428161Z","iopub.execute_input":"2024-08-25T14:13:51.428425Z","iopub.status.idle":"2024-08-25T14:13:51.439156Z","shell.execute_reply.started":"2024-08-25T14:13:51.428403Z","shell.execute_reply":"2024-08-25T14:13:51.438312Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# albumentations.Compose([albumentations.Transpose(p=0.5),albumentations.CoarseDropout(max_holes= 3,max_height = int(image_size * 0.375),min_holes = 0,max_width =int(image_size * 0.375),p=0.7 )])","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.440374Z","iopub.execute_input":"2024-08-25T14:13:51.442297Z","iopub.status.idle":"2024-08-25T14:13:51.448314Z","shell.execute_reply.started":"2024-08-25T14:13:51.442263Z","shell.execute_reply":"2024-08-25T14:13:51.447474Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# EfficientNetB0 = 224\n# EfficientNetB1 = 240\n# EfficientNetB2 = 260","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.449464Z","iopub.execute_input":"2024-08-25T14:13:51.449738Z","iopub.status.idle":"2024-08-25T14:13:51.457813Z","shell.execute_reply.started":"2024-08-25T14:13:51.449716Z","shell.execute_reply":"2024-08-25T14:13:51.456993Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# trans_train, trans_test =  get_transforms(EfficientNetB0)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.458825Z","iopub.execute_input":"2024-08-25T14:13:51.459110Z","iopub.status.idle":"2024-08-25T14:13:51.466441Z","shell.execute_reply.started":"2024-08-25T14:13:51.459087Z","shell.execute_reply":"2024-08-25T14:13:51.465597Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Features","metadata":{}},{"cell_type":"code","source":"# dataset_features = df_train.columns.to_list()\n# training_features = list(set(dataset_features)-set(['target','isic_id','iddx_full']))\n# test_val_features = list(set(dataset_features)-set(['target','iddx_full','isic_id']))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.467474Z","iopub.execute_input":"2024-08-25T14:13:51.467702Z","iopub.status.idle":"2024-08-25T14:13:51.474644Z","shell.execute_reply.started":"2024-08-25T14:13:51.467681Z","shell.execute_reply":"2024-08-25T14:13:51.473823Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split as tts\n\n\n# Train, Valid = tts(df_train, test_size = 0.03, stratify = df_train['target'],random_state=42)\n\n# print(f\"Train Shape is: {Train.shape}\")\n# print(f\"Valid Shape is: {Valid.shape}\")\n\n# print(f\"Validation and Test Len is {(Valid.shape[0] ) / df_train.shape[0] :.2%}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.475622Z","iopub.execute_input":"2024-08-25T14:13:51.475923Z","iopub.status.idle":"2024-08-25T14:13:51.488882Z","shell.execute_reply.started":"2024-08-25T14:13:51.475900Z","shell.execute_reply":"2024-08-25T14:13:51.487892Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"# train_ds = MelanomaDataset(Train,'train',training_features ,transform = trans_train)\n# valid_ds = MelanomaDataset(Valid,'valid',test_val_features,transform = trans_test)\n\n# train_dl = DataLoader(train_ds, batch_size = 32, shuffle = True)\n# valid_dl = DataLoader(valid_ds, batch_size = 32, shuffle = False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.490119Z","iopub.execute_input":"2024-08-25T14:13:51.490434Z","iopub.status.idle":"2024-08-25T14:13:51.499164Z","shell.execute_reply.started":"2024-08-25T14:13:51.490405Z","shell.execute_reply":"2024-08-25T14:13:51.498326Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# iterator = iter(train_dl)\n# (images,features),targets = next(iterator)\n# features.shape\n# images.shape\n# images = images.numpy()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.500192Z","iopub.execute_input":"2024-08-25T14:13:51.500458Z","iopub.status.idle":"2024-08-25T14:13:51.509230Z","shell.execute_reply.started":"2024-08-25T14:13:51.500436Z","shell.execute_reply":"2024-08-25T14:13:51.508367Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# def show_batch(image_batch, label_batch,cols=5):\n#     plt.figure(figsize=(20,20))\n#     num_images = image_batch.shape[0]\n#     num_rows = int(np.ceil(num_images / cols))\n#     for n in range(len(image_batch)):\n#         ax = plt.subplot(num_rows,cols,n+1)\n#         plt.imshow(image_batch[n].transpose(1, 2, 0))\n#         plt.title(label_batch[n])\n#         plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.510228Z","iopub.execute_input":"2024-08-25T14:13:51.510475Z","iopub.status.idle":"2024-08-25T14:13:51.519573Z","shell.execute_reply.started":"2024-08-25T14:13:51.510448Z","shell.execute_reply":"2024-08-25T14:13:51.518790Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# show_batch(images,targets,cols=5)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.520539Z","iopub.execute_input":"2024-08-25T14:13:51.520788Z","iopub.status.idle":"2024-08-25T14:13:51.530342Z","shell.execute_reply.started":"2024-08-25T14:13:51.520767Z","shell.execute_reply":"2024-08-25T14:13:51.529433Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"# Prepare a Model","metadata":{}},{"cell_type":"code","source":"from timm import create_model\nfrom timm import list_models\nimport timm","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:51.531370Z","iopub.execute_input":"2024-08-25T14:13:51.531674Z","iopub.status.idle":"2024-08-25T14:13:55.108698Z","shell.execute_reply.started":"2024-08-25T14:13:51.531651Z","shell.execute_reply":"2024-08-25T14:13:55.107770Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Find list of available models","metadata":{}},{"cell_type":"code","source":"\nsigmoid = nn.Sigmoid()\n\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass Swish_Module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:55.109777Z","iopub.execute_input":"2024-08-25T14:13:55.110076Z","iopub.status.idle":"2024-08-25T14:13:55.116663Z","shell.execute_reply.started":"2024-08-25T14:13:55.110051Z","shell.execute_reply":"2024-08-25T14:13:55.115748Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"class Effnet_Melanoma(nn.Module):\n    def __init__(self, enet_type, out_dim, n_meta_features=0, n_meta_dim=[512, 128], pretrained=False,num_heads=2):\n        super(Effnet_Melanoma, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.effnet = timm.create_model(enet_type, pretrained=True)\n        self.dropouts = nn.ModuleList([\n            nn.Dropout(0.5) for _ in range(5)\n        ])\n        in_ch = self.effnet.classifier.in_features\n        \n        if n_meta_features > 0:\n            self.meta = nn.Sequential(\n                nn.Linear(n_meta_features, n_meta_dim[0]),\n                nn.BatchNorm1d(n_meta_dim[0]),\n                Swish_Module(),\n                nn.Dropout(p=0.3),\n                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n                nn.BatchNorm1d(n_meta_dim[1]),\n                Swish_Module(),\n            )\n            \n            self.reduce_dim = nn.Linear(in_ch, n_meta_dim[1])\n            self.cross_attention = nn.MultiheadAttention(embed_dim=n_meta_dim[1], num_heads=num_heads)\n            \n            in_ch = n_meta_dim[1]\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.effnet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = self.effnet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x).squeeze(-1).squeeze(-1)\n        if self.n_meta_features > 0:\n            \n            x_meta = self.meta(x_meta)\n            x_meta = x_meta.unsqueeze(1)\n            \n            x = self.reduce_dim(x)\n            x = x.unsqueeze(1)\n            \n            attn_output, _ = self.cross_attention(x, x_meta, x_meta)\n            x = attn_output.squeeze(1) \n            \n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = self.myfc(dropout(x))\n            else:\n                out += self.myfc(dropout(x))\n        out /= len(self.dropouts)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:55.118127Z","iopub.execute_input":"2024-08-25T14:13:55.118443Z","iopub.status.idle":"2024-08-25T14:13:55.134588Z","shell.execute_reply.started":"2024-08-25T14:13:55.118419Z","shell.execute_reply":"2024-08-25T14:13:55.133674Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"# Testing model working","metadata":{}},{"cell_type":"code","source":"# 1. Create a dummy dataset\nbatch_size = 4\nnum_meta_features = 10\nimage_height = 224\nimage_width = 224\nnum_classes = 5\n\n# Dummy images (Batch size, Channels, Height, Width)\ndummy_images = torch.randn(batch_size, 3, image_height, image_width)\n\n# Dummy metadata (Batch size, Number of meta features)\ndummy_meta = torch.randn(batch_size, num_meta_features)\n\n# 2. Initialize the model\nmodel = Effnet_Melanoma(enet_type='efficientnet_b2', \n                        out_dim=num_classes, \n                        n_meta_features=num_meta_features, \n                        n_meta_dim=[512, 128], \n                        num_heads=4, \n                        pretrained=False)\n\n# 3. Forward pass\noutputs = model(dummy_images, dummy_meta)\n\n# Print the output\nprint(\"Model output shape:\", outputs.shape)  # Should be (batch_size, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:55.135664Z","iopub.execute_input":"2024-08-25T14:13:55.135956Z","iopub.status.idle":"2024-08-25T14:13:56.403722Z","shell.execute_reply.started":"2024-08-25T14:13:55.135932Z","shell.execute_reply":"2024-08-25T14:13:56.402798Z"},"trusted":true},"execution_count":58,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/36.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"555d1650376d410fa589a02b4134e8f4"}},"metadata":{}},{"name":"stdout","text":"Model output shape: torch.Size([4, 5])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Model architecture is fine ☺️","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.405108Z","iopub.execute_input":"2024-08-25T14:13:56.405476Z","iopub.status.idle":"2024-08-25T14:13:56.411751Z","shell.execute_reply.started":"2024-08-25T14:13:56.405443Z","shell.execute_reply":"2024-08-25T14:13:56.410846Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Training Config","metadata":{}},{"cell_type":"code","source":"class args:\n    DEBUG = False\n    model_dir = '/kaggle/working/model/'\n    log_dir = '/kaggle/working/logs/'\n    kernel_type = 'kag'\n    batch_size = 32\n    out_dim = 2\n    n_epochs = 2\n    num_workers = 2\n    use_amp = False\n    enet_type = 'efficientnet_b2'\n    dp = False\n    image_size = 224\n    data_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n    folded_data_path = '/kaggle/working/folded_metadata.csv'\n    n_splits = 2\n    n_meta_dim = [512,128]\n    init_lr = 0.002\n    fold = [0,1]\n    CUDA_VISIBLE_DEVICES = '0'\n    use_meta = True\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.412888Z","iopub.execute_input":"2024-08-25T14:13:56.413242Z","iopub.status.idle":"2024-08-25T14:13:56.422499Z","shell.execute_reply.started":"2024-08-25T14:13:56.413202Z","shell.execute_reply":"2024-08-25T14:13:56.421692Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Let's decide scheduler epochs. ","metadata":{}},{"cell_type":"code","source":"def partial_auc(validation_gt, v_predict,min_tpr: float=0.80):\n    \n    v_gt = abs(np.asarray(validation_gt)-1)\n\n    # flip the submissions to their compliments\n    v_pred = -1.0*np.asarray(v_predict)\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n\n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n    return(partial_auc)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.423495Z","iopub.execute_input":"2024-08-25T14:13:56.423814Z","iopub.status.idle":"2024-08-25T14:13:56.434340Z","shell.execute_reply.started":"2024-08-25T14:13:56.423782Z","shell.execute_reply":"2024-08-25T14:13:56.433485Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"### Test Validation function","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\nvalidation_gt = np.random.randint(0, 2, 100)  # Random ground truth labels (0 or 1)\nv_predict = np.random.rand(100)  # Random predicted probabilities between 0 and 1\n\n# Test the function\nresult = partial_auc(validation_gt, v_predict, min_tpr=0.80)\nprint(f\"Partial AUC: {result:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.435325Z","iopub.execute_input":"2024-08-25T14:13:56.435552Z","iopub.status.idle":"2024-08-25T14:13:56.455883Z","shell.execute_reply.started":"2024-08-25T14:13:56.435532Z","shell.execute_reply":"2024-08-25T14:13:56.455011Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Partial AUC: 0.0159\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer,use_meta= False):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n\n        optimizer.zero_grad()\n        \n        if use_meta:\n            data, meta = data\n            data, meta, target = data.to(device), meta.to(device), target.to(device)\n            logits = model(data, meta)\n        else:\n            data, target = data.to(device), target.to(device)\n            logits = model(data)        \n        \n        loss = criterion(logits, target)\n\n        loss.backward()\n        \n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n\n    train_loss = np.mean(train_loss)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.456949Z","iopub.execute_input":"2024-08-25T14:13:56.457292Z","iopub.status.idle":"2024-08-25T14:13:56.467575Z","shell.execute_reply.started":"2024-08-25T14:13:56.457267Z","shell.execute_reply":"2024-08-25T14:13:56.466695Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"def get_trans(img, I):\n\n    if I >= 4:\n        img = img.transpose(2, 3)\n    if I % 4 == 0:\n        return img\n    elif I % 4 == 1:\n        return img.flip(2)\n    elif I % 4 == 2:\n        return img.flip(3)\n    elif I % 4 == 3:\n        return img.flip(2).flip(3)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.468665Z","iopub.execute_input":"2024-08-25T14:13:56.469204Z","iopub.status.idle":"2024-08-25T14:13:56.481367Z","shell.execute_reply.started":"2024-08-25T14:13:56.469173Z","shell.execute_reply":"2024-08-25T14:13:56.480640Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"def val_epoch(model, loader, mel_idx=1, is_ext=None, n_test=1, get_output=False,use_meta= False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PROBS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            \n            if use_meta:\n                data, meta = data\n                data, meta, target = data.to(device), meta.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I), meta)\n                    logits += l\n                    probs += l.softmax(1)\n            else:\n                data, target = data.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    logits += l\n                    probs += l.softmax(1)\n            logits /= n_test\n            probs /= n_test\n\n            LOGITS.append(logits.detach().cpu())\n            PROBS.append(probs.detach().cpu())\n            TARGETS.append(target.detach().cpu())\n\n            loss = criterion(logits, target) # loss function internally applies softmax and use target as index to adjust loss\n            val_loss.append(loss.detach().cpu().numpy())\n\n    val_loss = np.mean(val_loss)\n    LOGITS = torch.cat(LOGITS).numpy()\n    PROBS = torch.cat(PROBS).numpy()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS, PROBS\n    else:\n        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n        auc = partial_auc((TARGETS == mel_idx).astype(float), PROBS[:, mel_idx]) # is_ext is 1-d array of 0 and 1. mel_idx is 1\n        #auc_20 = roc_auc_score((TARGETS[is_ext == 0] == mel_idx).astype(float), PROBS[is_ext == 0, mel_idx])\n        return val_loss, acc, auc\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.482603Z","iopub.execute_input":"2024-08-25T14:13:56.482894Z","iopub.status.idle":"2024-08-25T14:13:56.497966Z","shell.execute_reply.started":"2024-08-25T14:13:56.482867Z","shell.execute_reply":"2024-08-25T14:13:56.497052Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":" !pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:13:56.499154Z","iopub.execute_input":"2024-08-25T14:13:56.499498Z","iopub.status.idle":"2024-08-25T14:14:11.813191Z","shell.execute_reply.started":"2024-08-25T14:13:56.499469Z","shell.execute_reply":"2024-08-25T14:14:11.812191Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n  Cloning https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to /tmp/pip-req-build-fthjpu67\n  Running command git clone --filter=blob:none --quiet https://github.com/ildoonet/pytorch-gradual-warmup-lr.git /tmp/pip-req-build-fthjpu67\n  Resolved https://github.com/ildoonet/pytorch-gradual-warmup-lr.git to commit 6b5e8953a80aef5b324104dc0c2e9b8c34d622bd\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: warmup_scheduler\n  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3.2-py3-none-any.whl size=3865 sha256=8eb24f5962ace3eb28fc5c5886bf78ccdb049b89d0623d2285c3b484f32da7d9\n  Stored in directory: /tmp/pip-ephem-wheel-cache-0iysrk79/wheels/49/78/e6/9168d5844935482a171c7880a0626fa1c6c412b55666635f59\nSuccessfully built warmup_scheduler\nInstalling collected packages: warmup_scheduler\nSuccessfully installed warmup_scheduler-0.3.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Fix Warmup Bug\nfrom warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr\n\n\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:11.814663Z","iopub.execute_input":"2024-08-25T14:14:11.814994Z","iopub.status.idle":"2024-08-25T14:14:11.828676Z","shell.execute_reply.started":"2024-08-25T14:14:11.814954Z","shell.execute_reply":"2024-08-25T14:14:11.827908Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split as tts","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:19:06.167150Z","iopub.execute_input":"2024-08-25T14:19:06.167885Z","iopub.status.idle":"2024-08-25T14:19:06.172356Z","shell.execute_reply.started":"2024-08-25T14:19:06.167853Z","shell.execute_reply":"2024-08-25T14:19:06.171505Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"def run(fold, df, meta_features, n_meta_features, transforms_train, transforms_val, mel_idx):\n\n    if args.DEBUG:\n        df_train = df[df['fold'] != fold].sample(args.batch_size * 3)\n        df_valid = df[df['fold'] == fold].sample(args.batch_size * 500)\n    else:\n         df_train, df_valid = tts(df, test_size = 0.05, stratify = df['target'],random_state=42)\n#         df_train = df[df['fold'] != fold]\n#         df_valid = df[df['fold'] == fold]\n\n    dataset_train = MelanomaDataset(df_train, 'train', meta_features, transform=transforms_train)\n    dataset_valid = MelanomaDataset(df_valid, 'valid', meta_features, transform=transforms_val)\n    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, sampler=RandomSampler(dataset_train), num_workers=args.num_workers)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=args.batch_size, num_workers=args.num_workers)\n\n    model = ModelClass(\n        enet_type = args.enet_type,\n        out_dim=args.out_dim,\n        n_meta_features=n_meta_features,\n        n_meta_dim=args.n_meta_dim,\n        num_heads=2, \n        pretrained=True\n    )\n    \n    if args.dp:\n        model = apex.parallel.convert_syncbn_model(model)\n    model = model.to(device)\n\n    auc_max = 0.\n    #auc_20_max = 0.\n    model_file  = os.path.join(args.model_dir, f'{args.kernel_type}_best_fold{fold}.pth')\n    #model_file2 = os.path.join(args.model_dir, f'{args.kernel_type}_best_20_fold{fold}.pth')\n    model_file3 = os.path.join(args.model_dir, f'{args.kernel_type}_final_fold{fold}.pth')\n\n    optimizer = optim.Adam(model.parameters(), lr=args.init_lr)\n    \n    if args.use_amp:\n        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n    if args.dp:\n        model = nn.DataParallel(model)\n#     scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs - 1)\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, args.n_epochs - 1)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n    \n    print(len(dataset_train), len(dataset_valid))\n\n    for epoch in range(1, args.n_epochs + 1):\n        print(time.ctime(), f'Fold {fold}, Epoch {epoch}')\n\n        train_loss = train_epoch(model, train_loader, optimizer,use_meta = args.use_meta)\n        val_loss, acc, auc = val_epoch(model, valid_loader, mel_idx,use_meta = args.use_meta)\n\n        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}, auc: {(auc):.6f}.'\n        print(content)\n        with open(os.path.join(args.log_dir, f'log_{args.kernel_type}.txt'), 'a') as appender:\n            appender.write(content + '\\n')\n\n        scheduler_warmup.step()    \n        if epoch==2: scheduler_warmup.step() # bug workaround   \n            \n        if auc > auc_max:\n            print('auc_max ({:.6f} --> {:.6f}). Saving model ...'.format(auc_max, auc))\n            torch.save(model.state_dict(), model_file)\n            auc_max = auc\n\n    torch.save(model.state_dict(), model_file3)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:21:37.940001Z","iopub.execute_input":"2024-08-25T14:21:37.941022Z","iopub.status.idle":"2024-08-25T14:21:37.957680Z","shell.execute_reply.started":"2024-08-25T14:21:37.940987Z","shell.execute_reply":"2024-08-25T14:21:37.956506Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup and training","metadata":{}},{"cell_type":"code","source":"print(\"Number of GPUs available:\", torch.cuda.device_count())\nfor i in range(torch.cuda.device_count()):\n    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:11.848370Z","iopub.execute_input":"2024-08-25T14:14:11.848702Z","iopub.status.idle":"2024-08-25T14:14:11.914878Z","shell.execute_reply.started":"2024-08-25T14:14:11.848672Z","shell.execute_reply":"2024-08-25T14:14:11.914025Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Number of GPUs available: 1\nGPU 0: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"os.makedirs(args.model_dir, exist_ok=True)\nos.makedirs(args.log_dir, exist_ok=True)\nos.environ['CUDA_VISIBLE_DEVICES'] = args.CUDA_VISIBLE_DEVICES\n\nif args.enet_type == 'resnest101':\n    ModelClass = Resnest_Melanoma\nelif args.enet_type == 'seresnext101':\n    ModelClass = Seresnext_Melanoma\nelif 'efficientnet' in args.enet_type:\n    ModelClass = Effnet_Melanoma\nelse:\n    raise NotImplementedError()\n\nDP = len(os.environ['CUDA_VISIBLE_DEVICES']) > 1\nprint(os.environ['CUDA_VISIBLE_DEVICES'])\nset_seed()\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:11.915957Z","iopub.execute_input":"2024-08-25T14:14:11.916255Z","iopub.status.idle":"2024-08-25T14:14:11.924717Z","shell.execute_reply.started":"2024-08-25T14:14:11.916230Z","shell.execute_reply":"2024-08-25T14:14:11.923860Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create Fold of data","metadata":{}},{"cell_type":"code","source":"def createFold(data_path,output_path,n_splits = 1):\n    df = pd.read_csv(data_path)\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    for i, (_, val_index) in enumerate(skf.split(df, df[\"target\"])):\n        df.loc[val_index, \"fold\"] = i\n    df.to_csv(output_path,index= False)\n    return ","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:11.925782Z","iopub.execute_input":"2024-08-25T14:14:11.926039Z","iopub.status.idle":"2024-08-25T14:14:11.934813Z","shell.execute_reply.started":"2024-08-25T14:14:11.926013Z","shell.execute_reply":"2024-08-25T14:14:11.933942Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"markdown","source":"# Training of data","metadata":{}},{"cell_type":"code","source":"df, meta_features, n_meta_features, mel_idx = get_df(\n    args.data_path,\n    args.use_meta\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:11.936092Z","iopub.execute_input":"2024-08-25T14:14:11.936539Z","iopub.status.idle":"2024-08-25T14:14:27.155186Z","shell.execute_reply.started":"2024-08-25T14:14:11.936509Z","shell.execute_reply":"2024-08-25T14:14:27.154356Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":72,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/116039321.py:2: DtypeWarning: Columns (51,52) have mixed types. Specify dtype option on import or set low_memory=False.\n  df = pd.read_csv(data_dir)\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n/tmp/ipykernel_35/1874307831.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n","output_type":"stream"}]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=args.n_splits, shuffle=True, random_state=42)\nfor i, (_, val_index) in enumerate(skf.split(df, df[\"target\"])):\n    df.loc[val_index, \"fold\"] = i","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.156338Z","iopub.execute_input":"2024-08-25T14:14:27.156795Z","iopub.status.idle":"2024-08-25T14:14:27.247781Z","shell.execute_reply.started":"2024-08-25T14:14:27.156764Z","shell.execute_reply":"2024-08-25T14:14:27.246892Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4237610015.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df.loc[val_index, \"fold\"] = i\n","output_type":"stream"}]},{"cell_type":"code","source":"# if os.path.isfile(args.folded_data_path):\n#     print(\"Folded CSV files already exists\")\n# else:\n#     createFold(args.data_path,args.folded_data_path,args.n_splits)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.248778Z","iopub.execute_input":"2024-08-25T14:14:27.249040Z","iopub.status.idle":"2024-08-25T14:14:27.253205Z","shell.execute_reply.started":"2024-08-25T14:14:27.249017Z","shell.execute_reply":"2024-08-25T14:14:27.252330Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"df[df['fold']==1]","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.254392Z","iopub.execute_input":"2024-08-25T14:14:27.254713Z","iopub.status.idle":"2024-08-25T14:14:27.480663Z","shell.execute_reply.started":"2024-08-25T14:14:27.254682Z","shell.execute_reply":"2024-08-25T14:14:27.479736Z"},"trusted":true},"execution_count":75,"outputs":[{"execution_count":75,"output_type":"execute_result","data":{"text/plain":"             isic_id  target  age_approx  clin_size_long_diam_mm  tbp_lv_A  \\\n0       ISIC_0015670       0    0.145624               -0.511069  0.067613   \n2       ISIC_0015864       0    0.145624               -0.304536  0.650540   \n6       ISIC_0051648       0    0.514637               -0.109478 -1.413887   \n8       ISIC_0051710       0   -0.592403               -0.436488 -1.451988   \n11      ISIC_0051822       0    0.145624               -0.321747  0.007553   \n...              ...     ...         ...                     ...       ...   \n401046  ISIC_9999696       0   -0.223390                1.376409 -0.121130   \n401047  ISIC_9999762       0    0.514637               -0.482384 -1.055563   \n401051  ISIC_9999854       0    0.883650               -0.465173  0.365170   \n401054  ISIC_9999937       0    0.883650                1.646049  0.650166   \n401055  ISIC_9999951       0    0.145624               -0.470910  0.000908   \n\n        tbp_lv_Aext  tbp_lv_B  tbp_lv_Bext  tbp_lv_C  tbp_lv_Cext  ...  \\\n0          0.380443 -0.257500    -0.659882 -0.192995    -0.407543  ...   \n2          0.625867  1.835454     1.466075  1.644677     1.385391  ...   \n6         -1.377894 -0.302433    -0.795449 -0.788651    -1.139002  ...   \n8         -1.073714 -0.101933    -0.740825 -0.636770    -1.001354  ...   \n11         0.508759 -0.097369    -0.137003 -0.098681     0.049662  ...   \n...             ...       ...          ...       ...          ...  ...   \n401046    -1.162728 -0.502014    -0.337762 -0.453103    -0.686541  ...   \n401047    -0.777532 -0.468271    -0.507767 -0.796924    -0.712395  ...   \n401051     0.034160  1.329199     0.827603  1.140426     0.661741  ...   \n401054     0.007202 -0.117160    -0.032541  0.160952    -0.054822  ...   \n401055     0.313829  1.113374     0.914313  0.838322     0.825604  ...   \n\n        tbp_lv_location_Unknown  tbp_lv_location_simple_Head_&_  \\\n0                           0.0                             0.0   \n2                           0.0                             0.0   \n6                           0.0                             0.0   \n8                           0.0                             0.0   \n11                          0.0                             0.0   \n...                         ...                             ...   \n401046                      0.0                             0.0   \n401047                      0.0                             0.0   \n401051                      0.0                             0.0   \n401054                      0.0                             0.0   \n401055                      0.0                             0.0   \n\n        tbp_lv_location_simple_Left_Ar  tbp_lv_location_simple_Left_Le  \\\n0                                  0.0                             0.0   \n2                                  0.0                             0.0   \n6                                  0.0                             0.0   \n8                                  0.0                             0.0   \n11                                 0.0                             0.0   \n...                                ...                             ...   \n401046                             0.0                             0.0   \n401047                             0.0                             0.0   \n401051                             0.0                             0.0   \n401054                             0.0                             0.0   \n401055                             0.0                             0.0   \n\n        tbp_lv_location_simple_Right_A  tbp_lv_location_simple_Right_L  \\\n0                                  0.0                             1.0   \n2                                  0.0                             0.0   \n6                                  1.0                             0.0   \n8                                  0.0                             0.0   \n11                                 0.0                             0.0   \n...                                ...                             ...   \n401046                             0.0                             0.0   \n401047                             0.0                             0.0   \n401051                             0.0                             0.0   \n401054                             0.0                             0.0   \n401055                             0.0                             0.0   \n\n        tbp_lv_location_simple_Torso_B  tbp_lv_location_simple_Torso_F  \\\n0                                  0.0                             0.0   \n2                                  1.0                             0.0   \n6                                  0.0                             0.0   \n8                                  0.0                             1.0   \n11                                 1.0                             0.0   \n...                                ...                             ...   \n401046                             0.0                             1.0   \n401047                             0.0                             1.0   \n401051                             1.0                             0.0   \n401054                             0.0                             1.0   \n401055                             1.0                             0.0   \n\n        tbp_lv_location_simple_Unknown  fold  \n0                                  0.0   1.0  \n2                                  0.0   1.0  \n6                                  0.0   1.0  \n8                                  0.0   1.0  \n11                                 0.0   1.0  \n...                                ...   ...  \n401046                             0.0   1.0  \n401047                             0.0   1.0  \n401051                             0.0   1.0  \n401054                             0.0   1.0  \n401055                             0.0   1.0  \n\n[200529 rows x 118 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isic_id</th>\n      <th>target</th>\n      <th>age_approx</th>\n      <th>clin_size_long_diam_mm</th>\n      <th>tbp_lv_A</th>\n      <th>tbp_lv_Aext</th>\n      <th>tbp_lv_B</th>\n      <th>tbp_lv_Bext</th>\n      <th>tbp_lv_C</th>\n      <th>tbp_lv_Cext</th>\n      <th>...</th>\n      <th>tbp_lv_location_Unknown</th>\n      <th>tbp_lv_location_simple_Head_&amp;_</th>\n      <th>tbp_lv_location_simple_Left_Ar</th>\n      <th>tbp_lv_location_simple_Left_Le</th>\n      <th>tbp_lv_location_simple_Right_A</th>\n      <th>tbp_lv_location_simple_Right_L</th>\n      <th>tbp_lv_location_simple_Torso_B</th>\n      <th>tbp_lv_location_simple_Torso_F</th>\n      <th>tbp_lv_location_simple_Unknown</th>\n      <th>fold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ISIC_0015670</td>\n      <td>0</td>\n      <td>0.145624</td>\n      <td>-0.511069</td>\n      <td>0.067613</td>\n      <td>0.380443</td>\n      <td>-0.257500</td>\n      <td>-0.659882</td>\n      <td>-0.192995</td>\n      <td>-0.407543</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ISIC_0015864</td>\n      <td>0</td>\n      <td>0.145624</td>\n      <td>-0.304536</td>\n      <td>0.650540</td>\n      <td>0.625867</td>\n      <td>1.835454</td>\n      <td>1.466075</td>\n      <td>1.644677</td>\n      <td>1.385391</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>ISIC_0051648</td>\n      <td>0</td>\n      <td>0.514637</td>\n      <td>-0.109478</td>\n      <td>-1.413887</td>\n      <td>-1.377894</td>\n      <td>-0.302433</td>\n      <td>-0.795449</td>\n      <td>-0.788651</td>\n      <td>-1.139002</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ISIC_0051710</td>\n      <td>0</td>\n      <td>-0.592403</td>\n      <td>-0.436488</td>\n      <td>-1.451988</td>\n      <td>-1.073714</td>\n      <td>-0.101933</td>\n      <td>-0.740825</td>\n      <td>-0.636770</td>\n      <td>-1.001354</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ISIC_0051822</td>\n      <td>0</td>\n      <td>0.145624</td>\n      <td>-0.321747</td>\n      <td>0.007553</td>\n      <td>0.508759</td>\n      <td>-0.097369</td>\n      <td>-0.137003</td>\n      <td>-0.098681</td>\n      <td>0.049662</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>401046</th>\n      <td>ISIC_9999696</td>\n      <td>0</td>\n      <td>-0.223390</td>\n      <td>1.376409</td>\n      <td>-0.121130</td>\n      <td>-1.162728</td>\n      <td>-0.502014</td>\n      <td>-0.337762</td>\n      <td>-0.453103</td>\n      <td>-0.686541</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>401047</th>\n      <td>ISIC_9999762</td>\n      <td>0</td>\n      <td>0.514637</td>\n      <td>-0.482384</td>\n      <td>-1.055563</td>\n      <td>-0.777532</td>\n      <td>-0.468271</td>\n      <td>-0.507767</td>\n      <td>-0.796924</td>\n      <td>-0.712395</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>401051</th>\n      <td>ISIC_9999854</td>\n      <td>0</td>\n      <td>0.883650</td>\n      <td>-0.465173</td>\n      <td>0.365170</td>\n      <td>0.034160</td>\n      <td>1.329199</td>\n      <td>0.827603</td>\n      <td>1.140426</td>\n      <td>0.661741</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>401054</th>\n      <td>ISIC_9999937</td>\n      <td>0</td>\n      <td>0.883650</td>\n      <td>1.646049</td>\n      <td>0.650166</td>\n      <td>0.007202</td>\n      <td>-0.117160</td>\n      <td>-0.032541</td>\n      <td>0.160952</td>\n      <td>-0.054822</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>401055</th>\n      <td>ISIC_9999951</td>\n      <td>0</td>\n      <td>0.145624</td>\n      <td>-0.470910</td>\n      <td>0.000908</td>\n      <td>0.313829</td>\n      <td>1.113374</td>\n      <td>0.914313</td>\n      <td>0.838322</td>\n      <td>0.825604</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200529 rows × 118 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# pd.set_option('display.max_rows', 5)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.481852Z","iopub.execute_input":"2024-08-25T14:14:27.482511Z","iopub.status.idle":"2024-08-25T14:14:27.486034Z","shell.execute_reply.started":"2024-08-25T14:14:27.482483Z","shell.execute_reply":"2024-08-25T14:14:27.485150Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"# df.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.487105Z","iopub.execute_input":"2024-08-25T14:14:27.487387Z","iopub.status.idle":"2024-08-25T14:14:27.497248Z","shell.execute_reply.started":"2024-08-25T14:14:27.487357Z","shell.execute_reply":"2024-08-25T14:14:27.496403Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"\ntransforms_train, transforms_val = get_transforms(args.image_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.498339Z","iopub.execute_input":"2024-08-25T14:14:27.498599Z","iopub.status.idle":"2024-08-25T14:14:27.510086Z","shell.execute_reply.started":"2024-08-25T14:14:27.498576Z","shell.execute_reply":"2024-08-25T14:14:27.509248Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/transforms.py:180: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import warnings\n\n# Suppress specific FutureWarning\nwarnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"Series.__getitem__ treating keys as positions is deprecated\")","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:14:27.511230Z","iopub.execute_input":"2024-08-25T14:14:27.511531Z","iopub.status.idle":"2024-08-25T14:14:27.517618Z","shell.execute_reply.started":"2024-08-25T14:14:27.511496Z","shell.execute_reply":"2024-08-25T14:14:27.516848Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# for fold in args.fold:\n#     run(fold, df, meta_features, n_meta_features, transforms_train, transforms_val, mel_idx)\nrun(0, df, meta_features, n_meta_features, transforms_train, transforms_val, mel_idx)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T14:21:41.540508Z","iopub.execute_input":"2024-08-25T14:21:41.541199Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"381006 20053\nSun Aug 25 14:21:43 2024 Fold 0, Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/11907 [00:00<?, ?it/s]/tmp/ipykernel_35/1474287496.py:12: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n  i = ctx.saved_variables[0]\nloss: 0.00266, smth: 0.00387: 100%|██████████| 11907/11907 [1:05:38<00:00,  3.02it/s]\n100%|██████████| 627/627 [01:44<00:00,  5.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Sun Aug 25 15:29:06 2024 Fold 0, Epoch 1, lr: 0.0020000, train loss: 0.01045, valid loss: 0.00834, acc: 99.9003, auc: 0.009325.\nauc_max (0.000000 --> 0.009325). Saving model ...\nSun Aug 25 15:29:06 2024 Fold 0, Epoch 2\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/11907 [00:00<?, ?it/s]/tmp/ipykernel_35/1474287496.py:12: DeprecationWarning: 'saved_variables' is deprecated; use 'saved_tensors'\n  i = ctx.saved_variables[0]\nloss: 0.00000, smth: 0.00000:  13%|█▎        | 1505/11907 [07:18<45:01,  3.85it/s]       ","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}