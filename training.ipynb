{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":9219211,"sourceType":"datasetVersion","datasetId":5448479}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-24T08:27:57.219397Z","iopub.execute_input":"2024-08-24T08:27:57.219808Z","iopub.status.idle":"2024-08-24T08:27:57.251870Z","shell.execute_reply.started":"2024-08-24T08:27:57.219777Z","shell.execute_reply":"2024-08-24T08:27:57.250487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport polars as pl\n\nfrom sklearn.model_selection import StratifiedGroupKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import VotingClassifier\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.pipeline import Pipeline\n\nimport lightgbm as lgb\nimport catboost as cb\nimport xgboost as xgb\n\nimport optuna\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport albumentations\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom tqdm import tqdm\nimport cv2\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.image as mpimg\n\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data.sampler import RandomSampler, SequentialSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport apex\nfrom apex import amp","metadata":{"execution":{"iopub.status.busy":"2024-08-24T16:18:44.456740Z","iopub.execute_input":"2024-08-24T16:18:44.457158Z","iopub.status.idle":"2024-08-24T16:18:44.469444Z","shell.execute_reply.started":"2024-08-24T16:18:44.457123Z","shell.execute_reply":"2024-08-24T16:18:44.467971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traindf= pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.835247Z","iopub.execute_input":"2024-08-24T08:28:00.835751Z","iopub.status.idle":"2024-08-24T08:28:00.840328Z","shell.execute_reply.started":"2024-08-24T08:28:00.835720Z","shell.execute_reply":"2024-08-24T08:28:00.839241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traindf['iddx_full']","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.843004Z","iopub.execute_input":"2024-08-24T08:28:00.843948Z","iopub.status.idle":"2024-08-24T08:28:00.854704Z","shell.execute_reply.started":"2024-08-24T08:28:00.843908Z","shell.execute_reply":"2024-08-24T08:28:00.853664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Will use idx full as target column","metadata":{}},{"cell_type":"markdown","source":"## Find category relation between target and idX_full","metadata":{}},{"cell_type":"code","source":"# # Group by 'target' and get unique values in 'iddx_full'\n# unique_values = traindf.groupby('target')['iddx_full'].unique()\n\n# # Convert the result to a dictionary for better readability\n# unique_values_dict = unique_values.to_dict()\n\n# print(\"Unique values of 'iddx_full' for each category in 'target':\")\n# print(unique_values_dict[1])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.856039Z","iopub.execute_input":"2024-08-24T08:28:00.856579Z","iopub.status.idle":"2024-08-24T08:28:00.867004Z","shell.execute_reply.started":"2024-08-24T08:28:00.856543Z","shell.execute_reply":"2024-08-24T08:28:00.866124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(unique_values_dict[0])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.868178Z","iopub.execute_input":"2024-08-24T08:28:00.868516Z","iopub.status.idle":"2024-08-24T08:28:00.882534Z","shell.execute_reply.started":"2024-08-24T08:28:00.868490Z","shell.execute_reply":"2024-08-24T08:28:00.881466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Remove Not required columns","metadata":{}},{"cell_type":"code","source":"test_na_columns = [\n    \"lesion_id\",\n    \"iddx_1\",\n    \"iddx_2\",\n    \"iddx_3\",\n    \"iddx_4\",\n    \"iddx_5\",\n    \"mel_mitotic_index\",\n    \"mel_thick_mm\",\n    \"tbp_lv_dnn_lesion_confidence\",\n    \"copyright_license\",\n    \"attribution\",\n    \"patient_id\",\n    \"image_type\"\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:05.396539Z","iopub.execute_input":"2024-08-24T10:12:05.397150Z","iopub.status.idle":"2024-08-24T10:12:05.403314Z","shell.execute_reply.started":"2024-08-24T10:12:05.397112Z","shell.execute_reply":"2024-08-24T10:12:05.401918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tdf  = traindf.drop(columns = test_na_columns)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.894241Z","iopub.execute_input":"2024-08-24T08:28:00.894568Z","iopub.status.idle":"2024-08-24T08:28:00.903861Z","shell.execute_reply.started":"2024-08-24T08:28:00.894542Z","shell.execute_reply":"2024-08-24T08:28:00.902754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tdf.columns","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.907596Z","iopub.execute_input":"2024-08-24T08:28:00.907915Z","iopub.status.idle":"2024-08-24T08:28:00.913943Z","shell.execute_reply.started":"2024-08-24T08:28:00.907888Z","shell.execute_reply":"2024-08-24T08:28:00.912912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Look for column with missing values","metadata":{}},{"cell_type":"code","source":"# cols_with_nulls = traindf.columns[traindf.isnull().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.916594Z","iopub.execute_input":"2024-08-24T08:28:00.916908Z","iopub.status.idle":"2024-08-24T08:28:00.923801Z","shell.execute_reply.started":"2024-08-24T08:28:00.916882Z","shell.execute_reply":"2024-08-24T08:28:00.922744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# traindf['sex'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.925053Z","iopub.execute_input":"2024-08-24T08:28:00.925852Z","iopub.status.idle":"2024-08-24T08:28:00.934478Z","shell.execute_reply.started":"2024-08-24T08:28:00.925823Z","shell.execute_reply":"2024-08-24T08:28:00.933605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Numeric column with null values remove ","metadata":{}},{"cell_type":"code","source":"# tdf['tbp_lv_location_simple'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.935649Z","iopub.execute_input":"2024-08-24T08:28:00.935938Z","iopub.status.idle":"2024-08-24T08:28:00.945935Z","shell.execute_reply.started":"2024-08-24T08:28:00.935913Z","shell.execute_reply":"2024-08-24T08:28:00.944864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tdf['anatom_site_general'].mode()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.947154Z","iopub.execute_input":"2024-08-24T08:28:00.947538Z","iopub.status.idle":"2024-08-24T08:28:00.955684Z","shell.execute_reply.started":"2024-08-24T08:28:00.947507Z","shell.execute_reply":"2024-08-24T08:28:00.954829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tdf['age_approx'].median()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.956987Z","iopub.execute_input":"2024-08-24T08:28:00.957454Z","iopub.status.idle":"2024-08-24T08:28:00.967314Z","shell.execute_reply.started":"2024-08-24T08:28:00.957419Z","shell.execute_reply":"2024-08-24T08:28:00.966195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  tdf['age_approx'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.968585Z","iopub.execute_input":"2024-08-24T08:28:00.968944Z","iopub.status.idle":"2024-08-24T08:28:00.978617Z","shell.execute_reply.started":"2024-08-24T08:28:00.968916Z","shell.execute_reply":"2024-08-24T08:28:00.977699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  tdf['anatom_site_general'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.979846Z","iopub.execute_input":"2024-08-24T08:28:00.980178Z","iopub.status.idle":"2024-08-24T08:28:00.989406Z","shell.execute_reply.started":"2024-08-24T08:28:00.980151Z","shell.execute_reply":"2024-08-24T08:28:00.988245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  tdf['sex'].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:00.990901Z","iopub.execute_input":"2024-08-24T08:28:00.991696Z","iopub.status.idle":"2024-08-24T08:28:01.000189Z","shell.execute_reply.started":"2024-08-24T08:28:00.991659Z","shell.execute_reply":"2024-08-24T08:28:00.999241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read training Data","metadata":{}},{"cell_type":"code","source":"root = Path('/kaggle/input/isic-2024-challenge')\n\ntrain_path = root / 'train-metadata.csv'\ntest_path = root / 'test-metadata.csv'\nsubm_path = root / 'sample_submission.csv'\n\nid_col = 'isic_id'\ntarget_col = 'iddx_full'\ngroup_col = 'patient_id'\n\nerr = 1e-5\nsampling_ratio = 0.01\nseed = 42\n\nnum_cols = [\n    'age_approx',                        # Approximate age of patient at time of imaging.\n    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n    'tbp_lv_A',                          # A inside  lesion.+\n    'tbp_lv_Aext',                       # A outside lesion.+\n    'tbp_lv_B',                          # B inside  lesion.+\n    'tbp_lv_Bext',                       # B outside lesion.+ \n    'tbp_lv_C',                          # Chroma inside  lesion.+\n    'tbp_lv_Cext',                       # Chroma outside lesion.+\n    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n    'tbp_lv_Hext',                       # Hue outside lesion.+\n    'tbp_lv_L',                          # L inside lesion.+\n    'tbp_lv_Lext',                       # L outside lesion.+\n    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n    'tbp_lv_deltaLB',                    #\n    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n    'tbp_lv_eccentricity',               # Eccentricity.+\n    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n]\n\nnew_num_cols = [\n    'lesion_size_ratio',             # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n    'lesion_shape_index',            # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n    'hue_contrast',                  # tbp_lv_H                - tbp_lv_Hext              abs\n    'luminance_contrast',            # tbp_lv_L                - tbp_lv_Lext              abs\n    'lesion_color_difference',       # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt  \n    'border_complexity',             # tbp_lv_norm_border      + tbp_lv_symm_2axis\n    'color_uniformity',              # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n\n    'position_distance_3d',          # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n    'perimeter_to_area_ratio',       # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n    'area_to_perimeter_ratio',       # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n    'lesion_visibility_score',       # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n    'symmetry_border_consistency',   # tbp_lv_symm_2axis       * tbp_lv_norm_border\n    'consistency_symmetry_border',   # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n\n    'color_consistency',             # tbp_lv_stdL             / tbp_lv_Lext\n    'consistency_color',             # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n    'size_age_interaction',          # clin_size_long_diam_mm  * age_approx\n    'hue_color_std_interaction',     # tbp_lv_H                * tbp_lv_color_std_mean\n    'lesion_severity_index',         # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n    'shape_complexity_index',        # border_complexity       + lesion_shape_index\n    'color_contrast_index',          # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n\n    'log_lesion_area',               # tbp_lv_areaMM2          + 1  np.log\n    'normalized_lesion_size',        # clin_size_long_diam_mm  / age_approx\n    'mean_hue_difference',           # tbp_lv_H                + tbp_lv_Hext    / 2\n    'std_dev_contrast',              # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n    'color_shape_composite_index',   # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n    'lesion_orientation_3d',         # tbp_lv_y                , tbp_lv_x  np.arctan2\n    'overall_color_difference',      # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n\n    'symmetry_perimeter_interaction',# tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n    'comprehensive_lesion_index',    # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n    'color_variance_ratio',          # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n    'border_color_interaction',      # tbp_lv_norm_border      * tbp_lv_norm_color\n    'border_color_interaction_2',\n    'size_color_contrast_ratio',     # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n    'age_normalized_nevi_confidence',# tbp_lv_nevi_confidence  / age_approx\n    'age_normalized_nevi_confidence_2',\n    'color_asymmetry_index',         # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n\n    'volume_approximation_3d',       # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n    'color_range',                   # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n    'shape_color_consistency',       # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n    'border_length_ratio',           # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n    'age_size_symmetry_index',       # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n    'index_age_size_symmetry',       # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n]\n\ncat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple']\nfeature_cols = num_cols + new_num_cols + cat_cols ","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:11.429804Z","iopub.execute_input":"2024-08-24T10:12:11.430241Z","iopub.status.idle":"2024-08-24T10:12:11.444440Z","shell.execute_reply.started":"2024-08-24T10:12:11.430208Z","shell.execute_reply":"2024-08-24T10:12:11.443210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(new_num_cols)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:39.273444Z","iopub.execute_input":"2024-08-24T10:12:39.274533Z","iopub.status.idle":"2024-08-24T10:12:39.282328Z","shell.execute_reply.started":"2024-08-24T10:12:39.274485Z","shell.execute_reply":"2024-08-24T10:12:39.281116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_data(path):\n    return (\n        pl.DataFrame(path)\n        .with_columns(\n            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n        )\n        .with_columns(\n            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n        )\n        .with_columns(\n            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n        )\n        .with_columns(\n            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n        )\n        .with_columns(\n            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .with_columns(\n            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n        )\n        .to_pandas()\n    )","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:40.457996Z","iopub.execute_input":"2024-08-24T10:12:40.458410Z","iopub.status.idle":"2024-08-24T10:12:40.481500Z","shell.execute_reply.started":"2024-08-24T10:12:40.458377Z","shell.execute_reply":"2024-08-24T10:12:40.480255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess(df_train,is_test = False):\n\n    global cat_cols\n\n    df_train.drop(columns = test_na_columns,inplace=True)\n\n    # Select numerical columns\n    numerical_cols = df_train.select_dtypes(include=['number']).columns.tolist()\n    \n    # Initialize the scaler\n    scaler = StandardScaler()\n    numerical_cols.remove('target')\n    # Fit the scaler on the numerical data and transform\n    df_train[numerical_cols] = scaler.fit_transform(df_train[numerical_cols])\n\n    # Save the scaler object\n    with open('scaler.pkl', 'wb') as file:\n        pickle.dump(scaler, file)\n\n    encoder = OneHotEncoder(sparse_output=False)\n    encoder.fit(df_train[cat_cols])\n\n    MAX_CAT_VAR_NAME_SIZE = 30\n    new_cat_cols = [x.replace(\" \", \"_\")[:MAX_CAT_VAR_NAME_SIZE] for x in encoder.get_feature_names_out()]\n\n    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n        \n    for col in cat_cols:\n        feature_cols.remove(col)\n\n    df_train.drop(columns = cat_cols,inplace=True)\n\n    feature_cols.extend(new_cat_cols)\n    cat_cols = new_cat_cols\n\n    if is_test == False:\n        enc = OrdinalEncoder()\n        enc.fit(df_train[[target_col]])\n        df_train[target_col] = enc.transform(df_train[[target_col]])\n        with open('ordinalEndoder.pkl', 'wb') as file:\n            pickle.dump(enc, file)\n\n    return df_train","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:55.943518Z","iopub.execute_input":"2024-08-24T10:12:55.944267Z","iopub.status.idle":"2024-08-24T10:12:55.954433Z","shell.execute_reply.started":"2024-08-24T10:12:55.944229Z","shell.execute_reply":"2024-08-24T10:12:55.953216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df(data_dir,use_meta):\n    df = pd.read_csv(data_dir)\n\n    mode_values = df.select_dtypes(include=['object']).mode().iloc[0]\n    df.fillna(mode_values, inplace=True)\n\n    median_values = df.select_dtypes(include=['number']).median()\n\n    # Fill null values with the median values\n    df.fillna(median_values, inplace=True)\n    \n    df = read_data(df)\n    df = preprocess(df)\n    \n    if use_meta:\n        dataset_features = df.columns.to_list()\n        meta_features = list(set(dataset_features)-set(['target','isic_id','iddx_full']))\n        n_meta_features = len(meta_features)\n    else:\n        meta_features = None\n        n_meta_features = 0\n        \n    mel_idx = 1\n    return df, meta_features, n_meta_features, mel_idx","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(train_path)\n\n# mode_values = df_train.select_dtypes(include=['object']).mode().iloc[0]\n# df_train.fillna(mode_values, inplace=True)\n\n# median_values = df_train.select_dtypes(include=['number']).median()\n\n# # Fill null values with the median values\n# df_train.fillna(median_values, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:12:57.422756Z","iopub.execute_input":"2024-08-24T10:12:57.423813Z","iopub.status.idle":"2024-08-24T10:13:08.166551Z","shell.execute_reply.started":"2024-08-24T10:12:57.423752Z","shell.execute_reply":"2024-08-24T10:13:08.164972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = read_data(df_train)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:13:15.656040Z","iopub.execute_input":"2024-08-24T10:13:15.656456Z","iopub.status.idle":"2024-08-24T10:13:17.916354Z","shell.execute_reply.started":"2024-08-24T10:13:15.656425Z","shell.execute_reply":"2024-08-24T10:13:17.915304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = preprocess(df_train)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:13:19.407843Z","iopub.execute_input":"2024-08-24T10:13:19.408233Z","iopub.status.idle":"2024-08-24T10:13:22.001470Z","shell.execute_reply.started":"2024-08-24T10:13:19.408203Z","shell.execute_reply":"2024-08-24T10:13:22.000220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train.info()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:13:39.986647Z","iopub.execute_input":"2024-08-24T10:13:39.987819Z","iopub.status.idle":"2024-08-24T10:13:40.014966Z","shell.execute_reply.started":"2024-08-24T10:13:39.987750Z","shell.execute_reply":"2024-08-24T10:13:40.013431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train.columns[df_train.isnull().any()].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:13:45.274034Z","iopub.execute_input":"2024-08-24T10:13:45.274567Z","iopub.status.idle":"2024-08-24T10:13:45.358846Z","shell.execute_reply.started":"2024-08-24T10:13:45.274528Z","shell.execute_reply":"2024-08-24T10:13:45.357651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(df_train.columns.to_list())","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:13:46.414931Z","iopub.execute_input":"2024-08-24T10:13:46.415710Z","iopub.status.idle":"2024-08-24T10:13:46.420961Z","shell.execute_reply.started":"2024-08-24T10:13:46.415671Z","shell.execute_reply":"2024-08-24T10:13:46.419836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pd.set_option('display.max_rows', 60)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:14:51.598960Z","iopub.execute_input":"2024-08-24T10:14:51.599344Z","iopub.status.idle":"2024-08-24T10:14:51.604477Z","shell.execute_reply.started":"2024-08-24T10:14:51.599316Z","shell.execute_reply":"2024-08-24T10:14:51.603177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(len(df_train.columns.to_list()))","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:14:53.704945Z","iopub.execute_input":"2024-08-24T10:14:53.705390Z","iopub.status.idle":"2024-08-24T10:14:53.712806Z","shell.execute_reply.started":"2024-08-24T10:14:53.705357Z","shell.execute_reply":"2024-08-24T10:14:53.711382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train['index_age_size_symmetry'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:14:55.937145Z","iopub.execute_input":"2024-08-24T10:14:55.937550Z","iopub.status.idle":"2024-08-24T10:14:55.974412Z","shell.execute_reply.started":"2024-08-24T10:14:55.937517Z","shell.execute_reply":"2024-08-24T10:14:55.973275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train.iloc[10070].iddx_full","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:14:58.263869Z","iopub.execute_input":"2024-08-24T10:14:58.264995Z","iopub.status.idle":"2024-08-24T10:14:58.272164Z","shell.execute_reply.started":"2024-08-24T10:14:58.264947Z","shell.execute_reply":"2024-08-24T10:14:58.271073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train.to_csv('/kaggle/working/preprocessDataset.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:16.885643Z","iopub.status.idle":"2024-08-24T08:28:16.886017Z","shell.execute_reply.started":"2024-08-24T08:28:16.885828Z","shell.execute_reply":"2024-08-24T08:28:16.885844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train = pd.read_csv(train_path)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:16.888645Z","iopub.status.idle":"2024-08-24T08:28:16.889192Z","shell.execute_reply.started":"2024-08-24T08:28:16.888916Z","shell.execute_reply":"2024-08-24T08:28:16.888938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Removing the Psychic from dataset","metadata":{}},{"cell_type":"code","source":"# pdf = pd.read_csv('/kaggle/input/isic-2024-challenge/train-metadata.csv')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:07:04.880152Z","iopub.execute_input":"2024-08-24T12:07:04.880613Z","iopub.status.idle":"2024-08-24T12:07:11.189812Z","shell.execute_reply.started":"2024-08-24T12:07:04.880576Z","shell.execute_reply":"2024-08-24T12:07:11.188450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_selfclean = pd.read_csv('/kaggle/input/isic-2024-challenge-selfclean-scores/ISIC_2024_Challenge_SelfClean_Scores.csv')\n# df_selfclean.drop(columns=['irrelevant_ranking', 'label_error_ranking'], inplace=True)\n# df_selfclean.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:05:40.069153Z","iopub.execute_input":"2024-08-24T12:05:40.069607Z","iopub.status.idle":"2024-08-24T12:05:40.975023Z","shell.execute_reply.started":"2024-08-24T12:05:40.069576Z","shell.execute_reply":"2024-08-24T12:05:40.973825Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pdf = pdf.merge(df_selfclean, on=[\"isic_id\", \"patient_id\"])\n# pdf.head()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:07:32.291066Z","iopub.execute_input":"2024-08-24T12:07:32.291457Z","iopub.status.idle":"2024-08-24T12:07:33.116040Z","shell.execute_reply.started":"2024-08-24T12:07:32.291426Z","shell.execute_reply":"2024-08-24T12:07:33.114852Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pdf[\"label_error_score\"].hist(bins=\"sqrt\")\n# plt.yscale(\"log\")\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:17:52.490100Z","iopub.execute_input":"2024-08-24T12:17:52.490560Z","iopub.status.idle":"2024-08-24T12:17:54.003802Z","shell.execute_reply.started":"2024-08-24T12:17:52.490527Z","shell.execute_reply":"2024-08-24T12:17:54.002425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Remove Hair","metadata":{}},{"cell_type":"code","source":"#path_list = [f\"/kaggle/input/isic-2024-challenge/train-image/image/{id}.jpg\" for id in df_train.isic_id]","metadata":{"execution":{"iopub.status.busy":"2024-08-24T11:34:57.186164Z","iopub.execute_input":"2024-08-24T11:34:57.186558Z","iopub.status.idle":"2024-08-24T11:34:57.327677Z","shell.execute_reply.started":"2024-08-24T11:34:57.186528Z","shell.execute_reply":"2024-08-24T11:34:57.326563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#image_hair = np.array(path_list)[[1202, 216, 8854, 1174, 131, 174]]\n\ndef hair_remove(image):\n    # convert image to grayScale\n    grayScale = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n\n    # kernel for morphologyEx\n    kernel = cv2.getStructuringElement(1,(17,17))\n\n    # apply MORPH_BLACKHAT to grayScale image\n    blackhat = cv2.morphologyEx(grayScale, cv2.MORPH_BLACKHAT, kernel)\n\n    # apply thresholding to blackhat\n    _,threshold = cv2.threshold(blackhat,10,255,cv2.THRESH_BINARY)\n\n    # inpaint with original image and threshold image\n    final_image = cv2.inpaint(image,threshold,1,cv2.INPAINT_TELEA)\n\n    return final_image\n\n# Show the Augmented Images\n# plt.figure(figsize=(16,3))\n# plt.suptitle(\"Original Hairy Images\", fontsize = 16)\n    \n# for k, path in enumerate(image_hair[:5]):\n#     image = mpimg.imread(path)\n#     image = cv2.resize(image,(300, 300))\n        \n#     plt.subplot(1, 6, k+1)\n#     plt.imshow(image)\n#     plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:01:18.938279Z","iopub.execute_input":"2024-08-24T12:01:18.938712Z","iopub.status.idle":"2024-08-24T12:01:19.642396Z","shell.execute_reply.started":"2024-08-24T12:01:18.938675Z","shell.execute_reply":"2024-08-24T12:01:19.641113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Show the sample\n# plt.figure(figsize=(16,3))\n# plt.suptitle(\"Non Hairy Images\", fontsize = 16)\n    \n# for k, path in enumerate(image_hair):\n#     image = mpimg.imread(path)\n#     image = cv2.resize(image,(300, 300))\n#     image = hair_remove(image)\n        \n#     plt.subplot(1, 6, k+1)\n#     plt.imshow(image)\n#     plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:01:27.572120Z","iopub.execute_input":"2024-08-24T12:01:27.572531Z","iopub.status.idle":"2024-08-24T12:01:28.163820Z","shell.execute_reply.started":"2024-08-24T12:01:27.572497Z","shell.execute_reply":"2024-08-24T12:01:28.162526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# prepare dataset for iamges","metadata":{}},{"cell_type":"code","source":"class MelanomaDataset(Dataset):\n    def __init__(self, csv, mode, meta_features, transform=None):\n\n        self.csv = csv.reset_index(drop=True)\n        self.mode = mode\n        self.use_meta = meta_features is not None\n        self.meta_features = meta_features\n        self.transform = transform\n\n    def __len__(self):\n        return self.csv.shape[0]\n\n    def __getitem__(self, index):\n\n        row = self.csv.iloc[index]\n        #print(row)\n        train_image_base_path  = f'/kaggle/input/isic-2024-challenge/train-image/image/{row.isic_id}.jpg'\n        #print(\"filePath:\"+train_image_base_path)\n        image = cv2.imread(train_image_base_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        #image = hair_remove(image)\n        if self.transform is not None:\n            res = self.transform(image=image)\n            image = res['image'].astype(np.float32)\n        else:\n            image = image.astype(np.float32)\n\n        image = image.transpose(2, 0, 1)\n        #print(self.csv.iloc[index][self.meta_features])\n        if self.use_meta:\n            data = (torch.tensor(image).float(), torch.tensor(self.csv.iloc[index][self.meta_features]).float())\n        else:\n            data = torch.tensor(image).float()\n\n        if self.mode == 'test':\n            return data\n        else:\n            return data, torch.tensor(self.csv.iloc[index].target).float()","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:26:16.339883Z","iopub.execute_input":"2024-08-24T12:26:16.341075Z","iopub.status.idle":"2024-08-24T12:26:16.352050Z","shell.execute_reply.started":"2024-08-24T12:26:16.341035Z","shell.execute_reply":"2024-08-24T12:26:16.350849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(image_size):\n\n    transforms_train = albumentations.Compose([\n        albumentations.Transpose(p=0.5),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2,p=0.75),\n        albumentations.OneOf([\n            albumentations.MotionBlur(blur_limit=5),\n            albumentations.MedianBlur(blur_limit=5),\n            albumentations.GaussianBlur(blur_limit=5),\n            albumentations.GaussNoise(var_limit=(5.0, 30.0)),\n        ], p=0.7),\n\n        albumentations.OneOf([\n            albumentations.OpticalDistortion(distort_limit=1.0),\n            albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n            albumentations.ElasticTransform(alpha=3),\n        ], p=0.7),\n\n        albumentations.CLAHE(clip_limit=4.0, p=0.7),\n        #albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n        albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n        albumentations.Resize(image_size, image_size),\n        albumentations.CoarseDropout(max_holes= 3,max_height = int(image_size * 0.20),min_holes = 1,max_width =int(image_size * 0.20),p=0.7 ),\n        albumentations.Normalize()\n    ])\n\n    transforms_val = albumentations.Compose([\n        albumentations.Resize(image_size, image_size),\n        albumentations.Normalize()\n    ])\n\n    return transforms_train, transforms_val","metadata":{"execution":{"iopub.status.busy":"2024-08-24T11:44:21.850417Z","iopub.execute_input":"2024-08-24T11:44:21.850858Z","iopub.status.idle":"2024-08-24T11:44:21.860958Z","shell.execute_reply.started":"2024-08-24T11:44:21.850825Z","shell.execute_reply":"2024-08-24T11:44:21.859463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split and Prepare Dataset","metadata":{}},{"cell_type":"code","source":"# albumentations.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:16.899400Z","iopub.status.idle":"2024-08-24T08:28:16.899921Z","shell.execute_reply.started":"2024-08-24T08:28:16.899647Z","shell.execute_reply":"2024-08-24T08:28:16.899669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# albumentations.Compose([albumentations.Transpose(p=0.5),albumentations.CoarseDropout(max_holes= 3,max_height = int(image_size * 0.375),min_holes = 0,max_width =int(image_size * 0.375),p=0.7 )])","metadata":{"execution":{"iopub.status.busy":"2024-08-24T08:28:16.901616Z","iopub.status.idle":"2024-08-24T08:28:16.902155Z","shell.execute_reply.started":"2024-08-24T08:28:16.901872Z","shell.execute_reply":"2024-08-24T08:28:16.901895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EfficientNetB0 = 224\n# EfficientNetB1 = 240\n# EfficientNetB2 = 260","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:15:22.809015Z","iopub.execute_input":"2024-08-24T10:15:22.809433Z","iopub.status.idle":"2024-08-24T10:15:22.814955Z","shell.execute_reply.started":"2024-08-24T10:15:22.809399Z","shell.execute_reply":"2024-08-24T10:15:22.813783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# trans_train, trans_test =  get_transforms(EfficientNetB0)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:15:23.921926Z","iopub.execute_input":"2024-08-24T10:15:23.922311Z","iopub.status.idle":"2024-08-24T10:15:23.932097Z","shell.execute_reply.started":"2024-08-24T10:15:23.922282Z","shell.execute_reply":"2024-08-24T10:15:23.930646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train and Test Features","metadata":{}},{"cell_type":"code","source":"# dataset_features = df_train.columns.to_list()\n# training_features = list(set(dataset_features)-set(['target','isic_id','iddx_full']))\n# test_val_features = list(set(dataset_features)-set(['target','iddx_full','isic_id']))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:15:35.786650Z","iopub.execute_input":"2024-08-24T10:15:35.787077Z","iopub.status.idle":"2024-08-24T10:15:35.796517Z","shell.execute_reply.started":"2024-08-24T10:15:35.787044Z","shell.execute_reply":"2024-08-24T10:15:35.795209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split as tts\n\n\n# Train, Valid = tts(df_train, test_size = 0.03, stratify = df_train['target'],random_state=42)\n\n# print(f\"Train Shape is: {Train.shape}\")\n# print(f\"Valid Shape is: {Valid.shape}\")\n\n# print(f\"Validation and Test Len is {(Valid.shape[0] ) / df_train.shape[0] :.2%}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T10:15:37.795984Z","iopub.execute_input":"2024-08-24T10:15:37.796369Z","iopub.status.idle":"2024-08-24T10:15:38.605910Z","shell.execute_reply.started":"2024-08-24T10:15:37.796341Z","shell.execute_reply":"2024-08-24T10:15:38.604419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_ds = MelanomaDataset(Train,'train',training_features ,transform = trans_train)\n# valid_ds = MelanomaDataset(Valid,'valid',test_val_features,transform = trans_test)\n\n# train_dl = DataLoader(train_ds, batch_size = 32, shuffle = True)\n# valid_dl = DataLoader(valid_ds, batch_size = 32, shuffle = False)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:26:19.669198Z","iopub.execute_input":"2024-08-24T12:26:19.669606Z","iopub.status.idle":"2024-08-24T12:26:20.240086Z","shell.execute_reply.started":"2024-08-24T12:26:19.669573Z","shell.execute_reply":"2024-08-24T12:26:20.238787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# iterator = iter(train_dl)\n# (images,features),targets = next(iterator)\n# features.shape\n# images.shape\n# images = images.numpy()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T12:26:21.358748Z","iopub.execute_input":"2024-08-24T12:26:21.359566Z","iopub.status.idle":"2024-08-24T12:26:21.365149Z","shell.execute_reply.started":"2024-08-24T12:26:21.359530Z","shell.execute_reply":"2024-08-24T12:26:21.364018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def show_batch(image_batch, label_batch,cols=5):\n#     plt.figure(figsize=(20,20))\n#     num_images = image_batch.shape[0]\n#     num_rows = int(np.ceil(num_images / cols))\n#     for n in range(len(image_batch)):\n#         ax = plt.subplot(num_rows,cols,n+1)\n#         plt.imshow(image_batch[n].transpose(1, 2, 0))\n#         plt.title(label_batch[n])\n#         plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2024-08-24T11:44:41.904707Z","iopub.execute_input":"2024-08-24T11:44:41.905397Z","iopub.status.idle":"2024-08-24T11:44:41.912579Z","shell.execute_reply.started":"2024-08-24T11:44:41.905361Z","shell.execute_reply":"2024-08-24T11:44:41.911190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show_batch(images,targets,cols=5)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T11:46:28.379328Z","iopub.execute_input":"2024-08-24T11:46:28.379760Z","iopub.status.idle":"2024-08-24T11:46:32.282157Z","shell.execute_reply.started":"2024-08-24T11:46:28.379726Z","shell.execute_reply":"2024-08-24T11:46:32.280876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare a Model","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \n# Set seed\nseed_everything(SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from timm import create_model\nfrom timm import list_models\nimport timm","metadata":{"execution":{"iopub.status.busy":"2024-08-24T13:32:16.902723Z","iopub.execute_input":"2024-08-24T13:32:16.903125Z","iopub.status.idle":"2024-08-24T13:32:16.908540Z","shell.execute_reply.started":"2024-08-24T13:32:16.903092Z","shell.execute_reply":"2024-08-24T13:32:16.907352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Find list of available models","metadata":{}},{"cell_type":"code","source":"\nsigmoid = nn.Sigmoid()\n\n\nclass Swish(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, i):\n        result = i * sigmoid(i)\n        ctx.save_for_backward(i)\n        return result\n    @staticmethod\n    def backward(ctx, grad_output):\n        i = ctx.saved_variables[0]\n        sigmoid_i = sigmoid(i)\n        return grad_output * (sigmoid_i * (1 + i * (1 - sigmoid_i)))\n\n\nclass Swish_Module(nn.Module):\n    def forward(self, x):\n        return Swish.apply(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T15:13:20.165645Z","iopub.execute_input":"2024-08-24T15:13:20.166045Z","iopub.status.idle":"2024-08-24T15:13:20.174563Z","shell.execute_reply.started":"2024-08-24T15:13:20.166013Z","shell.execute_reply":"2024-08-24T15:13:20.173332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Effnet_Melanoma(nn.Module):\n    def __init__(self, enet_type, out_dim, n_meta_features=0, n_meta_dim=[512, 128], pretrained=False,num_heads=2):\n        super(Effnet_Melanoma, self).__init__()\n        self.n_meta_features = n_meta_features\n        self.effnet = timm.create_model(enet_type, pretrained=True)\n        self.dropouts = nn.ModuleList([\n            nn.Dropout(0.5) for _ in range(5)\n        ])\n        in_ch = self.effnet.classifier.in_features\n        \n        if n_meta_features > 0:\n            self.meta = nn.Sequential(\n                nn.Linear(n_meta_features, n_meta_dim[0]),\n                nn.BatchNorm1d(n_meta_dim[0]),\n                Swish_Module(),\n                nn.Dropout(p=0.3),\n                nn.Linear(n_meta_dim[0], n_meta_dim[1]),\n                nn.BatchNorm1d(n_meta_dim[1]),\n                Swish_Module(),\n            )\n            \n            self.reduce_dim = nn.Linear(in_ch, n_meta_dim[1])\n            self.cross_attention = nn.MultiheadAttention(embed_dim=n_meta_dim[1], num_heads=num_heads)\n            \n            in_ch = n_meta_dim[1]\n        self.myfc = nn.Linear(in_ch, out_dim)\n        self.effnet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = self.effnet(x)\n        return x\n\n    def forward(self, x, x_meta=None):\n        x = self.extract(x).squeeze(-1).squeeze(-1)\n        if self.n_meta_features > 0:\n            \n            x_meta = self.meta(x_meta)\n            x_meta = x_meta.unsqueeze(1)\n            \n            x = self.reduce_dim(x)\n            x = x.unsqueeze(1)\n            \n            attn_output, _ = self.cross_attention(x, x_meta, x_meta)\n            x = attn_output.squeeze(1) \n            \n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                out = self.myfc(dropout(x))\n            else:\n                out += self.myfc(dropout(x))\n        out /= len(self.dropouts)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-08-24T15:15:25.401982Z","iopub.execute_input":"2024-08-24T15:15:25.402408Z","iopub.status.idle":"2024-08-24T15:15:25.421339Z","shell.execute_reply.started":"2024-08-24T15:15:25.402375Z","shell.execute_reply":"2024-08-24T15:15:25.420130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing model working","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-08-24T16:18:27.868417Z","iopub.execute_input":"2024-08-24T16:18:27.868834Z","iopub.status.idle":"2024-08-24T16:18:27.874559Z","shell.execute_reply.started":"2024-08-24T16:18:27.868801Z","shell.execute_reply":"2024-08-24T16:18:27.873206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Create a dummy dataset\nbatch_size = 4\nnum_meta_features = 10\nimage_height = 224\nimage_width = 224\nnum_classes = 5\n\n# Dummy images (Batch size, Channels, Height, Width)\ndummy_images = torch.randn(batch_size, 3, image_height, image_width)\n\n# Dummy metadata (Batch size, Number of meta features)\ndummy_meta = torch.randn(batch_size, num_meta_features)\n\n# 2. Initialize the model\nmodel = Effnet_Melanoma(enet_type='efficientnet_b2', \n                        out_dim=num_classes, \n                        n_meta_features=num_meta_features, \n                        n_meta_dim=[512, 128], \n                        num_heads=4, \n                        pretrained=False)\n\n# 3. Forward pass\noutputs = model(dummy_images, dummy_meta)\n\n# Print the output\nprint(\"Model output shape:\", outputs.shape)  # Should be (batch_size, num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T16:18:30.293527Z","iopub.execute_input":"2024-08-24T16:18:30.294000Z","iopub.status.idle":"2024-08-24T16:18:31.433693Z","shell.execute_reply.started":"2024-08-24T16:18:30.293963Z","shell.execute_reply":"2024-08-24T16:18:31.431357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model architecture is fine ","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=0):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2024-08-25T10:00:48.793759Z","iopub.execute_input":"2024-08-25T10:00:48.794811Z","iopub.status.idle":"2024-08-25T10:00:48.809565Z","shell.execute_reply.started":"2024-08-25T10:00:48.794766Z","shell.execute_reply":"2024-08-25T10:00:48.807938Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Training Config","metadata":{}},{"cell_type":"code","source":"class args:\n    DEBUG = True\n    model_dir = '/kaggle/working/model/'\n    log_dir = '/kaggle/working/logs/'\n    kernel_type = 'kag'\n    batch_size = 32\n    out_dim = 2\n    n_epochs = 2\n    num_workers = 2\n    use_amp = False\n    n_meta_dim = \n    enet_type = 'efficientnet_b2'\n    dp = False\n    image_size = 224\n    data_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n    folded_data_path = '/kaggle/working/folded_metadata.csv'\n    n_splits = 1\n    n_meta_dim = [512,128]\n    init_lr = 0.002\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Let's decide scheduler epochs. ","metadata":{}},{"cell_type":"code","source":"def partial_auc(validation_gt, v_predict,min_tpr: float=0.80):\n    \n    v_gt = abs(np.asarray(validation_gt)-1)\n\n    # flip the submissions to their compliments\n    v_pred = -1.0*np.asarray(v_predict)\n\n    max_fpr = abs(1-min_tpr)\n\n    # using sklearn.metric functions: (1) roc_curve and (2) auc\n    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n    if max_fpr is None or max_fpr == 1:\n        return auc(fpr, tpr)\n    if max_fpr <= 0 or max_fpr > 1:\n        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n\n    # Add a single point at max_fpr by linear interpolation\n    stop = np.searchsorted(fpr, max_fpr, \"right\")\n    x_interp = [fpr[stop - 1], fpr[stop]]\n    y_interp = [tpr[stop - 1], tpr[stop]]\n    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n    fpr = np.append(fpr[:stop], max_fpr)\n    partial_auc = auc(fpr, tpr)\n    return(partial_auc)","metadata":{"execution":{"iopub.status.busy":"2024-08-24T16:19:08.050984Z","iopub.execute_input":"2024-08-24T16:19:08.051388Z","iopub.status.idle":"2024-08-24T16:19:08.061766Z","shell.execute_reply.started":"2024-08-24T16:19:08.051357Z","shell.execute_reply":"2024-08-24T16:19:08.060546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Validation function","metadata":{}},{"cell_type":"code","source":"np.random.seed(42)\nvalidation_gt = np.random.randint(0, 2, 100)  # Random ground truth labels (0 or 1)\nv_predict = np.random.rand(100)  # Random predicted probabilities between 0 and 1\n\n# Test the function\nresult = partial_auc(validation_gt, v_predict, min_tpr=0.80)\nprint(f\"Partial AUC: {result:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-24T16:19:09.786846Z","iopub.execute_input":"2024-08-24T16:19:09.787233Z","iopub.status.idle":"2024-08-24T16:19:09.803023Z","shell.execute_reply.started":"2024-08-24T16:19:09.787203Z","shell.execute_reply":"2024-08-24T16:19:09.801442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_epoch(model, loader, optimizer,use_meta= False):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n\n        optimizer.zero_grad()\n        \n        if use_meta:\n            data, meta = data\n            data, meta, target = data.to(device), meta.to(device), target.to(device)\n            logits = model(data, meta)\n        else:\n            data, target = data.to(device), target.to(device)\n            logits = model(data)        \n        \n        loss = criterion(logits, target)\n\n        loss.backward()\n        \n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n\n    train_loss = np.mean(train_loss)\n    return train_loss","metadata":{"execution":{"iopub.status.busy":"2024-08-24T15:33:22.413650Z","iopub.execute_input":"2024-08-24T15:33:22.414057Z","iopub.status.idle":"2024-08-24T15:33:22.425387Z","shell.execute_reply.started":"2024-08-24T15:33:22.414027Z","shell.execute_reply":"2024-08-24T15:33:22.424008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_trans(img, I):\n\n    if I >= 4:\n        img = img.transpose(2, 3)\n    if I % 4 == 0:\n        return img\n    elif I % 4 == 1:\n        return img.flip(2)\n    elif I % 4 == 2:\n        return img.flip(3)\n    elif I % 4 == 3:\n        return img.flip(2).flip(3)","metadata":{"execution":{"iopub.status.busy":"2024-08-25T08:24:02.938304Z","iopub.execute_input":"2024-08-25T08:24:02.938736Z","iopub.status.idle":"2024-08-25T08:24:02.979030Z","shell.execute_reply.started":"2024-08-25T08:24:02.938700Z","shell.execute_reply":"2024-08-25T08:24:02.977742Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def val_epoch(model, loader, mel_idx=1, is_ext=None, n_test=1, get_output=False,use_meta= False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PROBS = []\n    TARGETS = []\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            \n            if use_meta:\n                data, meta = data\n                data, meta, target = data.to(device), meta.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I), meta)\n                    logits += l\n                    probs += l.softmax(1)\n            else:\n                data, target = data.to(device), target.to(device)\n                logits = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                probs = torch.zeros((data.shape[0], args.out_dim)).to(device)\n                for I in range(n_test):\n                    l = model(get_trans(data, I))\n                    logits += l\n                    probs += l.softmax(1)\n            logits /= n_test\n            probs /= n_test\n\n            LOGITS.append(logits.detach().cpu())\n            PROBS.append(probs.detach().cpu())\n            TARGETS.append(target.detach().cpu())\n\n            loss = criterion(logits, target) # loss function internally applies softmax and use target as index to adjust loss\n            val_loss.append(loss.detach().cpu().numpy())\n\n    val_loss = np.mean(val_loss)\n    LOGITS = torch.cat(LOGITS).numpy()\n    PROBS = torch.cat(PROBS).numpy()\n    TARGETS = torch.cat(TARGETS).numpy()\n\n    if get_output:\n        return LOGITS, PROBS\n    else:\n        acc = (PROBS.argmax(1) == TARGETS).mean() * 100.\n        auc = partial_auc((TARGETS == mel_idx).astype(float), PROBS[:, mel_idx]) # is_ext is 1-d array of 0 and 1. mel_idx is 1\n        #auc_20 = roc_auc_score((TARGETS[is_ext == 0] == mel_idx).astype(float), PROBS[is_ext == 0, mel_idx])\n        return val_loss, acc, auc\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fix Warmup Bug\nfrom warmup_scheduler import GradualWarmupScheduler  # https://github.com/ildoonet/pytorch-gradual-warmup-lr\n\n\nclass GradualWarmupSchedulerV2(GradualWarmupScheduler):\n    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n        super(GradualWarmupSchedulerV2, self).__init__(optimizer, multiplier, total_epoch, after_scheduler)\n    def get_lr(self):\n        if self.last_epoch > self.total_epoch:\n            if self.after_scheduler:\n                if not self.finished:\n                    self.after_scheduler.base_lrs = [base_lr * self.multiplier for base_lr in self.base_lrs]\n                    self.finished = True\n                return self.after_scheduler.get_lr()\n            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n        if self.multiplier == 1.0:\n            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n        else:\n            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold, df, meta_features, n_meta_features, transforms_train, transforms_val, mel_idx):\n\n    if args.DEBUG:\n        df_train = df[df['fold'] != fold].sample(args.batch_size * 2)\n        df_valid = df[df['fold'] == fold].sample(args.batch_size * 2)\n    else:\n        df_train = df[df['fold'] != fold]\n        df_valid = df[df['fold'] == fold]\n\n    dataset_train = MelanomaDataset(df_train, 'train', meta_features, transform=transforms_train)\n    dataset_valid = MelanomaDataset(df_valid, 'valid', meta_features, transform=transforms_val)\n    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=args.batch_size, sampler=RandomSampler(dataset_train), num_workers=args.num_workers)\n    valid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=args.batch_size, num_workers=args.num_workers)\n\n    model = ModelClass(\n        enet_type = args.enet_type,\n        out_dim=args.out_dim,\n        n_meta_features=n_meta_features,\n        n_meta_dim=args.n_meta_dim\n        num_heads=2, \n        pretrained=True\n    )\n    \n    if args.dp:\n        model = apex.parallel.convert_syncbn_model(model)\n    model = model.to(device)\n\n    auc_max = 0.\n    #auc_20_max = 0.\n    model_file  = os.path.join(args.model_dir, f'{args.kernel_type}_best_fold{fold}.pth')\n    #model_file2 = os.path.join(args.model_dir, f'{args.kernel_type}_best_20_fold{fold}.pth')\n    model_file3 = os.path.join(args.model_dir, f'{args.kernel_type}_final_fold{fold}.pth')\n\n    optimizer = optim.Adam(model.parameters(), lr=args.init_lr)\n    \n    if args.use_amp:\n        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n    if args.dp:\n        model = nn.DataParallel(model)\n#     scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.n_epochs - 1)\n    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, args.n_epochs - 1)\n    scheduler_warmup = GradualWarmupSchedulerV2(optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n    \n    print(len(dataset_train), len(dataset_valid))\n\n    for epoch in range(1, args.n_epochs + 1):\n        print(time.ctime(), f'Fold {fold}, Epoch {epoch}')\n\n        train_loss = train_epoch(model, train_loader, optimizer)\n        val_loss, acc, auc = val_epoch(model, valid_loader, mel_idx)\n\n        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {(val_loss):.5f}, acc: {(acc):.4f}, auc: {(auc):.6f}, auc_20: {(auc_20):.6f}.'\n        print(content)\n        with open(os.path.join(args.log_dir, f'log_{args.kernel_type}.txt'), 'a') as appender:\n            appender.write(content + '\\n')\n\n        scheduler_warmup.step()    \n        if epoch==2: scheduler_warmup.step() # bug workaround   \n            \n        if auc > auc_max:\n            print('auc_max ({:.6f} --> {:.6f}). Saving model ...'.format(auc_max, auc))\n            torch.save(model.state_dict(), model_file)\n            auc_max = auc\n\n    torch.save(model.state_dict(), model_file3)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup and training","metadata":{}},{"cell_type":"code","source":"os.makedirs(args.model_dir, exist_ok=True)\nos.makedirs(args.log_dir, exist_ok=True)\nos.environ['CUDA_VISIBLE_DEVICES'] = args.CUDA_VISIBLE_DEVICES\n\nif args.enet_type == 'resnest101':\n    ModelClass = Resnest_Melanoma\nelif args.enet_type == 'seresnext101':\n    ModelClass = Seresnext_Melanoma\nelif 'efficientnet' in args.enet_type:\n    ModelClass = Effnet_Melanoma\nelse:\n    raise NotImplementedError()\n\nDP = len(os.environ['CUDA_VISIBLE_DEVICES']) > 1\nprint(os.environ['CUDA_VISIBLE_DEVICES'])\nset_seed()\n\ndevice = torch.device('cuda')\ncriterion = nn.CrossEntropyLoss()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Fold of data","metadata":{}},{"cell_type":"code","source":"def createFold(data_path,output_path,n_splits = 1):\n    df = pd.read_csv(data_path)\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n    for i, (_, val_index) in enumerate(skf.split(df, df[\"target\"])):\n        df.loc[val_index, \"fold\"] = i\n    df.to_csv(output_path,index= False)\n    return ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if os.path.isfile(args.folded_data_path):\n    print(\"Folded CSV files already exists\")\nelse:\n    createFold(args.data_path,args.folded_data_path,args.n_splits)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training of data","metadata":{}},{"cell_type":"code","source":"df, meta_features, n_meta_features, mel_idx = get_df(\n    args.folded_data_path,\n    args.use_meta\n)\n\ntransforms_train, transforms_val = get_transforms(args.image_size)\n\nfolds = [int(i) for i in args.fold.split(',')]\nfor fold in folds:\n    run(fold, df, meta_features, n_meta_features, transforms_train, transforms_val, mel_idx)","metadata":{},"execution_count":null,"outputs":[]}]}